{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "import cv2\n",
    "#from PIL import Image\n",
    "#import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Dimensions of the Training set: (125973, 42)</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Dimensions of the Test set: (22543, 42)</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Findout The categorical column & set of categories from Train Dataset:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'protocol_type' has 3 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'service' has 70 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'flag' has 11 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'labels' has 23 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Findout The categorical column & set of categories from Test Dataset:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'protocol_type' has 3 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'service' has 63 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'flag' has 11 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Dataset Column 'labels' has 38 categories</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Service Column has following Distribution of categories:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Service Type  </th><th style=\"text-align: right;\">  Count</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>http          </td><td style=\"text-align: right;\">  40338</td></tr>\n",
       "<tr><td>private       </td><td style=\"text-align: right;\">  21853</td></tr>\n",
       "<tr><td>domain_u      </td><td style=\"text-align: right;\">   9043</td></tr>\n",
       "<tr><td>smtp          </td><td style=\"text-align: right;\">   7313</td></tr>\n",
       "<tr><td>ftp_data      </td><td style=\"text-align: right;\">   6860</td></tr>\n",
       "<tr><td>eco_i         </td><td style=\"text-align: right;\">   4586</td></tr>\n",
       "<tr><td>other         </td><td style=\"text-align: right;\">   4359</td></tr>\n",
       "<tr><td>ecr_i         </td><td style=\"text-align: right;\">   3077</td></tr>\n",
       "<tr><td>telnet        </td><td style=\"text-align: right;\">   2353</td></tr>\n",
       "<tr><td>finger        </td><td style=\"text-align: right;\">   1767</td></tr>\n",
       "<tr><td>ftp           </td><td style=\"text-align: right;\">   1754</td></tr>\n",
       "<tr><td>auth          </td><td style=\"text-align: right;\">    955</td></tr>\n",
       "<tr><td>Z39_50        </td><td style=\"text-align: right;\">    862</td></tr>\n",
       "<tr><td>uucp          </td><td style=\"text-align: right;\">    780</td></tr>\n",
       "<tr><td>courier       </td><td style=\"text-align: right;\">    734</td></tr>\n",
       "<tr><td>bgp           </td><td style=\"text-align: right;\">    710</td></tr>\n",
       "<tr><td>whois         </td><td style=\"text-align: right;\">    693</td></tr>\n",
       "<tr><td>uucp_path     </td><td style=\"text-align: right;\">    689</td></tr>\n",
       "<tr><td>iso_tsap      </td><td style=\"text-align: right;\">    687</td></tr>\n",
       "<tr><td>time          </td><td style=\"text-align: right;\">    654</td></tr>\n",
       "<tr><td>imap4         </td><td style=\"text-align: right;\">    647</td></tr>\n",
       "<tr><td>nnsp          </td><td style=\"text-align: right;\">    630</td></tr>\n",
       "<tr><td>vmnet         </td><td style=\"text-align: right;\">    617</td></tr>\n",
       "<tr><td>urp_i         </td><td style=\"text-align: right;\">    602</td></tr>\n",
       "<tr><td>domain        </td><td style=\"text-align: right;\">    569</td></tr>\n",
       "<tr><td>ctf           </td><td style=\"text-align: right;\">    563</td></tr>\n",
       "<tr><td>csnet_ns      </td><td style=\"text-align: right;\">    545</td></tr>\n",
       "<tr><td>supdup        </td><td style=\"text-align: right;\">    544</td></tr>\n",
       "<tr><td>discard       </td><td style=\"text-align: right;\">    538</td></tr>\n",
       "<tr><td>http_443      </td><td style=\"text-align: right;\">    530</td></tr>\n",
       "<tr><td>daytime       </td><td style=\"text-align: right;\">    521</td></tr>\n",
       "<tr><td>gopher        </td><td style=\"text-align: right;\">    518</td></tr>\n",
       "<tr><td>efs           </td><td style=\"text-align: right;\">    485</td></tr>\n",
       "<tr><td>systat        </td><td style=\"text-align: right;\">    477</td></tr>\n",
       "<tr><td>link          </td><td style=\"text-align: right;\">    475</td></tr>\n",
       "<tr><td>exec          </td><td style=\"text-align: right;\">    474</td></tr>\n",
       "<tr><td>hostnames     </td><td style=\"text-align: right;\">    460</td></tr>\n",
       "<tr><td>name          </td><td style=\"text-align: right;\">    451</td></tr>\n",
       "<tr><td>mtp           </td><td style=\"text-align: right;\">    439</td></tr>\n",
       "<tr><td>echo          </td><td style=\"text-align: right;\">    434</td></tr>\n",
       "<tr><td>klogin        </td><td style=\"text-align: right;\">    433</td></tr>\n",
       "<tr><td>login         </td><td style=\"text-align: right;\">    429</td></tr>\n",
       "<tr><td>ldap          </td><td style=\"text-align: right;\">    410</td></tr>\n",
       "<tr><td>netbios_dgm   </td><td style=\"text-align: right;\">    405</td></tr>\n",
       "<tr><td>sunrpc        </td><td style=\"text-align: right;\">    381</td></tr>\n",
       "<tr><td>netbios_ssn   </td><td style=\"text-align: right;\">    362</td></tr>\n",
       "<tr><td>netstat       </td><td style=\"text-align: right;\">    360</td></tr>\n",
       "<tr><td>netbios_ns    </td><td style=\"text-align: right;\">    347</td></tr>\n",
       "<tr><td>ssh           </td><td style=\"text-align: right;\">    311</td></tr>\n",
       "<tr><td>kshell        </td><td style=\"text-align: right;\">    299</td></tr>\n",
       "<tr><td>nntp          </td><td style=\"text-align: right;\">    296</td></tr>\n",
       "<tr><td>pop_3         </td><td style=\"text-align: right;\">    264</td></tr>\n",
       "<tr><td>sql_net       </td><td style=\"text-align: right;\">    245</td></tr>\n",
       "<tr><td>IRC           </td><td style=\"text-align: right;\">    187</td></tr>\n",
       "<tr><td>ntp_u         </td><td style=\"text-align: right;\">    168</td></tr>\n",
       "<tr><td>rje           </td><td style=\"text-align: right;\">     86</td></tr>\n",
       "<tr><td>remote_job    </td><td style=\"text-align: right;\">     78</td></tr>\n",
       "<tr><td>pop_2         </td><td style=\"text-align: right;\">     78</td></tr>\n",
       "<tr><td>X11           </td><td style=\"text-align: right;\">     73</td></tr>\n",
       "<tr><td>printer       </td><td style=\"text-align: right;\">     69</td></tr>\n",
       "<tr><td>shell         </td><td style=\"text-align: right;\">     65</td></tr>\n",
       "<tr><td>urh_i         </td><td style=\"text-align: right;\">     10</td></tr>\n",
       "<tr><td>red_i         </td><td style=\"text-align: right;\">      8</td></tr>\n",
       "<tr><td>tim_i         </td><td style=\"text-align: right;\">      8</td></tr>\n",
       "<tr><td>pm_dump       </td><td style=\"text-align: right;\">      5</td></tr>\n",
       "<tr><td>tftp_u        </td><td style=\"text-align: right;\">      3</td></tr>\n",
       "<tr><td>harvest       </td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>aol           </td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>http_8001     </td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>http_2784     </td><td style=\"text-align: right;\">      1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset from CSV files\n",
    "Base_DIR=\"/Users/apatkar/Documents/LiverpoolProject\"\n",
    "TwentyPercentTrainDataurl = Base_DIR+\"/NSL_KDD-master-Original/20 Percent Training Set.csv\"\n",
    "KDDTestDataseturl = Base_DIR+\"/NSL_KDD-master-Original/KDDTest+.csv\"\n",
    "KDDTrainDataseturl = Base_DIR+\"/NSL_KDD-master-Original/KDDTrain+.csv\"\n",
    "\n",
    "# Load dataset from TXT files\n",
    "#TwentyPercentTrainDataurl = Base_DIR+\"/NSL_KDD-master/KDDTrain+_20Percent.txt\"\n",
    "#KDDTestDataseturl = Base_DIR+\"/NSL_KDD-master/KDDTest+.txt\"\n",
    "#KDDTrainDataseturl = Base_DIR+\"/NSL_KDD-master/KDDTrain+.txt\"\n",
    "\n",
    "names = ['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot',\n",
    "         'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n",
    "         'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count',\n",
    "         'serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n",
    "         'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "         'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate',\n",
    "         'dst_host_rerror_rate','dst_host_srv_rerror_rate','labels','dst_host_']\n",
    "\n",
    "# Use when Reading CSV files\n",
    "TwentyPercentTrainDataset = pandas.read_csv(TwentyPercentTrainDataurl, header=None, names=names)\n",
    "KDDTestDataset = pandas.read_csv(KDDTestDataseturl, header=None, names=names)\n",
    "KDDTrainDataset = pandas.read_csv(KDDTrainDataseturl, header=None, names=names)\n",
    "\n",
    "#Use When Reading Text Files\n",
    "#TwentyPercentTrainDataset = pandas.read_csv(TwentyPercentTrainDataurl, sep = \",\", names=names)\n",
    "#KDDTestDataset = pandas.read_csv(KDDTestDataseturl, sep = \",\", names=names)\n",
    "#KDDTrainDataset = pandas.read_csv(KDDTrainDataseturl, sep = \",\", names=names)\n",
    "\n",
    "#Copy Data set for Data Analysis\n",
    "#dataset = TwentyPercentTrainDataset\n",
    "#dataset = KDDTestDataset\n",
    "dataset = KDDTrainDataset\n",
    "\n",
    "#remove the last column\n",
    "KDDTrainDataset.pop('dst_host_')\n",
    "KDDTestDataset.pop('dst_host_')  \n",
    "TwentyPercentTrainDataset.pop('dst_host_') \n",
    "\n",
    "# shape, this gives the dimensions of the dataset\n",
    "display(HTML(\"<h3>Dimensions of the Training set: {TrainShape}</h3>\".format(TrainShape=KDDTrainDataset.shape)))\n",
    "display(HTML(\"<h3>Dimensions of the Test set: {TestShape}</h3>\".format(TestShape=KDDTestDataset.shape)))\n",
    "\n",
    "# Test set\n",
    "display(HTML('<h2>Findout The categorical column & set of categories from Train Dataset:</h2>'))\n",
    "for ColumnName in KDDTestDataset.columns:\n",
    "    if KDDTrainDataset[ColumnName].dtypes == 'object' :\n",
    "        UniqueCategory = len(KDDTrainDataset[ColumnName].unique())\n",
    "        display(HTML(\"<h4> Dataset Column '{ColumnName}' has {UniqueCategory} categories</h4>\".\n",
    "                     format(ColumnName=ColumnName, UniqueCategory=UniqueCategory)))\n",
    "display(HTML('<h2>Findout The categorical column & set of categories from Test Dataset:</h2>'))\n",
    "for ColumnName in KDDTestDataset.columns:\n",
    "    if KDDTestDataset[ColumnName].dtypes == 'object' :\n",
    "        UniqueCategory = len(KDDTestDataset[ColumnName].unique())\n",
    "        display(HTML(\"<h4> Dataset Column '{ColumnName}' has {UniqueCategory} categories</h4>\".\n",
    "                     format(ColumnName=ColumnName, UniqueCategory=UniqueCategory)))\n",
    "        \n",
    "# Find out the distribution of the Service category Which will help to decide on additional Dummy Columns\n",
    "display(HTML(\"<h2>Service Column has following Distribution of categories:</h2>\"))   \n",
    "display(HTML(tabulate.tabulate(pandas.DataFrame(KDDTrainDataset['service'].value_counts().sort_values(ascending=False)), \n",
    "                               headers=['Service Type','Count'], tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Look into the data using head command\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Printing 20 records from Training Dataset~~~~~~~~~~~~~~~~~~~\")\n",
    "display(HTML(tabulate.tabulate(KDDTrainDataset.head(20), headers=names, tablefmt='html')))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Printing 20 records from Test Dataset~~~~~~~~~~~~~~~~~~~\")\n",
    "display(HTML(tabulate.tabulate(KDDTestDataset.head(20), headers=names, tablefmt='html')))\n",
    "\n",
    "# Describe the data\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Printing Statistic Summary of Training Dataset~~~~~~~~~~~~~~~~~~~\")\n",
    "display(HTML(tabulate.tabulate(KDDTrainDataset.describe(), headers=names, tablefmt='html')))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Printing Statistic Summary of Test Dataset~~~~~~~~~~~~~~~~~~~\")\n",
    "display(HTML(tabulate.tabulate(KDDTestDataset.describe(), headers=names, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Distribution of the Training data set\n",
    "display(HTML(\"<h2>Lable Distribution across the Training dataset:</h2>\"))\n",
    "display(HTML(tabulate.tabulate(pandas.DataFrame(KDDTrainDataset['labels'].value_counts()), \n",
    "                               headers=['Attack Type','Count'], tablefmt='html')))\n",
    "display()\n",
    "# Label Distribution of the Test data set\n",
    "display(HTML(\"<h2>Lable Distribution across the Test dataset:</h2>\"))\n",
    "display(HTML(tabulate.tabulate(pandas.DataFrameDistributionColumns(KDDTestDataset['labels'].value_counts()), \n",
    "                               headers=['Attack Type','Count'], tablefmt='html')))\n",
    "display()\n",
    "# Check how Protocol Type Column attributes/values affects other data column\n",
    "pandas.crosstab(KDDTrainDataset[\"protocol_type\"],KDDTrainDataset[\"labels\"],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the Lable data by manipulating it to attck and normal categories\n",
    "\n",
    "dataset.loc[(dataset['labels'] !='normal'),'labels'] = 'attack'\n",
    "dataset.loc[(dataset['labels'] =='normal'),'labels'] = 'normal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcQAAADeCAYAAACjZXBWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bb86a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Pie Graph\n",
    "PieDataSet = pandas.crosstab(KDDTrainDataset[\"protocol_type\"],KDDTrainDataset[\"labels\"],margins=True)\n",
    "# Drop the Column Total\n",
    "PieDataSet.pop('All')\n",
    "# Drop The Row Total\n",
    "PieDataSet.drop(PieDataSet.tail(1).index,inplace=True)\n",
    "PieDataSet.plot.pie(subplots=True, colors=['r', 'c', 'b'], fontsize=12, figsize=(6, 3))\n",
    "plt.tight_layout(pad=0.4, w_pad=1.5, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a602eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAEhCAYAAADcRLFIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a602978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# box and whisker plots\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "dataset.plot(kind='box', subplots=True, grid=True, layout=(11,4), sharex=True, sharey=False,)\n",
    "#plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()\n",
    "\n",
    "#sns.boxplot(data=dataset, orient=\"h\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The BOX graph for Protocol type and Rumber Of Compromised Column group by attack or normal dataset\n",
    "BoxGraph = sns.FacetGrid(dataset, col=\"labels\", sharex=False)\n",
    "BoxGraph.map(sns.boxplot,\"num_compromised\", \"protocol_type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The BarGrapg\n",
    "sns.set(style='ticks', context='paper')\n",
    "BarGraph = sns.FacetGrid(dataset, col='labels', hue='labels', size=3)\n",
    "BarGraph.map(sns.barplot, 'num_compromised', 'protocol_type');\n",
    "plt.show()\n",
    "sns.barplot(x=\"num_compromised\", y=\"protocol_type\", hue=\"labels\", data=dataset);\n",
    "plt.show()\n",
    "dataset.plot.barh(stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The histograms\n",
    "dataset.hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The ScatterPlot\n",
    "Palette = dict(attack=\"seagreen\", normal=\"red\") #(tcp=\"seagreen\", udp=\"gray\", icmp=\"yellow\")\n",
    "ScatterPlot = sns.FacetGrid(dataset, hue=\"labels\", palette=Palette, size=5)\n",
    "ScatterPlot.map(plt.scatter, \"protocol_type\", \"num_compromised\", s=50, alpha=.7, linewidth=.5, edgecolor=\"white\")\n",
    "ScatterPlot.add_legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    g = sns.FacetGrid(dataset, row=\"protocol_type\", col=\"labels\", margin_titles=True, size=2.5)\n",
    "g.map(plt.scatter, \"num_failed_logins\", \"dst_host_count\", color=\"#334488\", edgecolor=\"white\", lw=.5); #num_compromised\n",
    "g.set_axis_labels(\"Failed Logins\", \"Numbers of Compromised\");\n",
    "g.set(xticks=[0, 5, 10], yticks=[0, 250, 500]);\n",
    "g.fig.subplots_adjust(wspace=.02, hspace=.02);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the test and train data\n",
    "traindata = pandas.read_csv(KDDTrainDataseturl, header=None, names=names)\n",
    "testdata = pandas.read_csv(KDDTestDataseturl, header=None, names=names)\n",
    "\n",
    "# Save Images of Normal and Attack data before we \n",
    "# Create Dummy Data Frame From the Training Data Set\n",
    "DummyDataFrame = traindata\n",
    "# Get the Lable Column from Dummy Data Frame\n",
    "LableColumnDataFrame=DummyDataFrame['labels']\n",
    "# change the label column 0=normal, 1=DoS, 2=Probe, 3=R2L and 4=U2R\n",
    "DummyDataFrame2=LableColumnDataFrame.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "\n",
    "# Add the modified label column back\n",
    "DummyDataFrame['labels'] = DummyDataFrame2\n",
    "# Filter Out The data by Lable\n",
    "DosData = DummyDataFrame.loc[DummyDataFrame['labels'] == 1]\n",
    "ProbData = DummyDataFrame.loc[DummyDataFrame['labels'] == 2]\n",
    "R2LData = DummyDataFrame.loc[DummyDataFrame['labels'] == 3]\n",
    "U2RData = DummyDataFrame.loc[DummyDataFrame['labels'] == 4]\n",
    "NormalData = DummyDataFrame.loc[DummyDataFrame['labels'] == 0]\n",
    "\n",
    "# Display statement to view the filtered data\n",
    "#display(HTML(tabulate.tabulate(DosData.head(5), tablefmt='html')))\n",
    "#display(HTML(tabulate.tabulate(ProbData.head(5), tablefmt='html')))\n",
    "#display(HTML(tabulate.tabulate(R2LData.head(5), tablefmt='html')))\n",
    "#display(HTML(tabulate.tabulate(U2RData.head(5), tablefmt='html')))\n",
    "#display(HTML(tabulate.tabulate(NormalData.head(5), tablefmt='html')))\n",
    "\n",
    "# Take the random smaple of fileterd out dataset for Image creation we are taking 3 randon rows\n",
    "frames = [DosData.sample(n=3, random_state=2), ProbData.sample(n=3, random_state=2), \n",
    "          R2LData.sample(n=3, random_state=2), U2RData.sample(n=3, random_state=2),\n",
    "          NormalData.sample(n=3, random_state=2)\n",
    "         ]\n",
    "# Join, Concatinate the diffrent filetred dDtaFrames\n",
    "ImageData = pandas.concat(frames)\n",
    "\n",
    "# Set the Protocol Type Column to Numeric values in DataFrame\n",
    "ImageData.loc[(dataset['protocol_type'] =='tcp'),'protocol_type'] = 1\n",
    "ImageData.loc[(dataset['protocol_type'] =='udp'),'protocol_type'] = 2\n",
    "ImageData.loc[(dataset['protocol_type'] =='icmp'),'protocol_type'] = 3\n",
    "# For this test Image coversion purpose change the Service & Flag column to zero in this dataframe\n",
    "ImageData.loc[(dataset['service'] !=''),'service'] = 0\n",
    "ImageData.loc[(dataset['flag'] !=''),'flag'] = 0\n",
    "\n",
    "# Set the Counter\n",
    "IDX = 0\n",
    "#print(ImageData.shape)\n",
    "for index, row in ImageData.iterrows():\n",
    "    # Get all the column data from the DataFrame row\n",
    "    IMGDT = ImageData.iloc[IDX,1:43]\n",
    "    #print(IMGDT)\n",
    "    # Get The Lable data to add to the name to identify type of attack image is for\n",
    "    RowType = IMGDT['labels']\n",
    "    # Convert the data to Numpy Array\n",
    "    IDT = np.array(IMGDT)\n",
    "    # Convert the data to Binary\n",
    "    ISA = np.select([IDT <= .5, IDT>.5], [np.zeros_like(IDT), np.ones_like(IDT)])\n",
    "    # Create the Numpy array of converted data\n",
    "    NPData = np.array(ISA * 255, dtype = np.uint8)\n",
    "    # Create a grayscale image using CV2 function\n",
    "    grayscale = cv2.adaptiveThreshold(NPData, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 0)\n",
    "    # Recsale created Grascale Image to 32x32\n",
    "    Image32_32 = cv2.resize(grayscale, (32,32))\n",
    "    # Add new axies/dimension to the image\n",
    "    Image32_32_1 = Image32_32[:, :, np.newaxis]\n",
    "    # Generate the Image Iname\n",
    "    imagename = 'IMG_'+str(IDX)+'_'+str(RowType)+'.png'\n",
    "    # Save Original and convered Image\n",
    "    cv2.imwrite(imagename,Image32_32_1)\n",
    "    cv2.imwrite('U'+imagename,grayscale)\n",
    "    #C lear up the Numply Array for next operation and increment the Index\n",
    "    np.delete(IDT, 1, 0)\n",
    "    IDX = IDX+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td>tcp</td><td>ftp_data</td><td>SF</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td>udp</td><td>other   </td><td>SF</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td>tcp</td><td>private </td><td>S0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td>tcp</td><td>http    </td><td>SF</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td>tcp</td><td>http    </td><td>SF</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td>tcp </td><td>private </td><td>REJ </td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td>tcp </td><td>private </td><td>REJ </td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td>tcp </td><td>ftp_data</td><td>SF  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td>icmp</td><td>eco_i   </td><td>SF  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td>tcp </td><td>telnet  </td><td>RSTO</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~Training Data Set Dummy Column List~~~~~~~~~~~~~~~~~~~\n",
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n",
      "~~~~~~~~~~~~~~~~~~~Testing Data Set Dummy Column List~~~~~~~~~~~~~~~~~~~\n",
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_hostnames', 'service_http', 'service_http_443', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tim_i', 'service_time', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">20</td><td style=\"text-align: right;\">9</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">44</td><td style=\"text-align: right;\">9</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">49</td><td style=\"text-align: right;\">5</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">24</td><td style=\"text-align: right;\">9</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">24</td><td style=\"text-align: right;\">9</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">45</td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">45</td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">19</td><td style=\"text-align: right;\">9</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">13</td><td style=\"text-align: right;\">9</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">55</td><td style=\"text-align: right;\">2</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 124)\n",
      "(22543, 124)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">491</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\"> 2</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">150</td><td style=\"text-align: right;\"> 25</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">0   </td><td>normal</td><td style=\"text-align: right;\">20</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">146</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 13</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">0.15</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.6 </td><td style=\"text-align: right;\">0.88</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td>normal</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">123</td><td style=\"text-align: right;\"> 6</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\"> 26</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td>attack</td><td style=\"text-align: right;\">19</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">232</td><td style=\"text-align: right;\">8153</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  5</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\"> 30</td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.01</td><td>normal</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">199</td><td style=\"text-align: right;\"> 420</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 30</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td>normal</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">229</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">1   </td><td>normal</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">136</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">1   </td><td>normal</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">12983</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">134</td><td style=\"text-align: right;\">86</td><td style=\"text-align: right;\">0.61</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.61</td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td>attack</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">65</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">57</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0.28</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td>normal</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 8</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.12</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.75</td><td style=\"text-align: right;\"> 29</td><td style=\"text-align: right;\">86</td><td style=\"text-align: right;\">0.31</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.83</td><td style=\"text-align: right;\">0.71</td><td>normal</td><td style=\"text-align: right;\">11</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "        \n",
    "# Get the Label column adjusted\n",
    "traindata.loc[(dataset['labels'] !='normal'),'labels'] = 'attack'\n",
    "traindata.loc[(dataset['labels'] =='normal'),'labels'] = 'normal'\n",
    "testdata.loc[(dataset['labels'] !='normal'),'labels'] = 'attack'\n",
    "testdata.loc[(dataset['labels'] =='normal'),'labels'] = 'normal'\n",
    "\n",
    "# A list of categorical columns into a variable, categorical_columns for training data\n",
    "CategoricalColumnsTrain=['protocol_type', 'service', 'flag']\n",
    "# A list of categorical columns into a variable, categorical_columns for test data\n",
    "CategoricalColumnsTest=['protocol_type', 'service', 'flag'] \n",
    " # Create a 2D numpy array of the categorical values\n",
    "TrainDataCategoricalValues = traindata[CategoricalColumnsTrain]\n",
    "display(HTML(tabulate.tabulate(TrainDataCategoricalValues.head(), tablefmt='html')))\n",
    "TestDataCategoricalValues = testdata[CategoricalColumnsTest]\n",
    "display(HTML(tabulate.tabulate(TestDataCategoricalValues.head(), tablefmt='html')))\n",
    "\n",
    "# Dummy column creation process\n",
    "# Create names for the dummy protocol type coumns\n",
    "UniqueProtocolName=sorted(traindata.protocol_type.unique())\n",
    "ColumnNameOne = 'Protocol_type_'\n",
    "UniqueProtocolNameList=[ColumnNameOne + x for x in UniqueProtocolName]\n",
    "# Create names for the dummy service columns\n",
    "UniqueServiceName=sorted(traindata.service.unique())\n",
    "ColumnNameTwo = 'service_'\n",
    "UniqueServiceNameList=[ColumnNameTwo + x for x in UniqueServiceName]\n",
    "# Create names for the dummy flag coulmns\n",
    "UniqueFlagValue=sorted(traindata.flag.unique())\n",
    "ColumnNameThree = 'flag_'\n",
    "UniqueFlagValueList=[ColumnNameThree + x for x in UniqueFlagValue]\n",
    "# Join all the dummy columns name\n",
    "TrainDummyColumnList=UniqueProtocolNameList + UniqueServiceNameList + UniqueFlagValueList\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Training Data Set Dummy Column List~~~~~~~~~~~~~~~~~~~\")\n",
    "print (TrainDummyColumnList)\n",
    "\n",
    "# do same for test set\n",
    "TestUniqueProtocolName=sorted(testdata.protocol_type.unique())\n",
    "TestUniqueProtocolNameList=[ColumnNameOne + x for x in TestUniqueProtocolName]\n",
    "TestUniqueServiceName=sorted(testdata.service.unique())\n",
    "TestUniqueServiceNameList=[ColumnNameTwo + x for x in TestUniqueServiceName]\n",
    "TestUniqueFlagValue=sorted(traindata.flag.unique())\n",
    "TestUniqueFlagValueList=[ColumnNameThree + x for x in TestUniqueFlagValue]\n",
    "TestDummyColumnList=TestUniqueProtocolNameList + TestUniqueServiceNameList + TestUniqueFlagValueList\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Testing Data Set Dummy Column List~~~~~~~~~~~~~~~~~~~\")\n",
    "print (TestDummyColumnList)\n",
    "\n",
    "# apply lable encoder to the created Dummy column values\n",
    "EncodedTrainDataCategoricalValues=TrainDataCategoricalValues.apply(LabelEncoder().fit_transform)\n",
    "display(HTML(tabulate.tabulate(EncodedTrainDataCategoricalValues.head(), tablefmt='html')))\n",
    "# perform same on the test set\n",
    "EncodedTestDataCategoricalValues=TestDataCategoricalValues.apply(LabelEncoder().fit_transform)\n",
    "display(HTML(tabulate.tabulate(EncodedTestDataCategoricalValues.head(), tablefmt='html')))\n",
    "\n",
    "# Apply one hot encoder to the dummy data\n",
    "OHEncoder = OneHotEncoder()\n",
    "EncodedTrainDataCategoricalValuesOHE = OHEncoder.fit_transform(EncodedTrainDataCategoricalValues)\n",
    "TrainCategoriesData = pandas.DataFrame(EncodedTrainDataCategoricalValuesOHE.toarray(),columns=TrainDummyColumnList)\n",
    "# Perform Same on the Test set\n",
    "EncodedTestDataCategoricalValuesOHE = OHEncoder.fit_transform(EncodedTestDataCategoricalValues)\n",
    "TestCategoriesData = pandas.DataFrame(EncodedTestDataCategoricalValuesOHE.toarray(),columns=TestDummyColumnList)\n",
    "\n",
    "TrainCategoriesData.head()\n",
    "\n",
    "TraingServiceList=traindata['service'].tolist()\n",
    "TestServiceList= testdata['service'].tolist()\n",
    "MissingServicesList=list(set(TraingServiceList) - set(TestServiceList))\n",
    "ServiceLable = 'service_'\n",
    "MissingServicesList=[ServiceLable + x for x in MissingServicesList]\n",
    "MissingServicesList\n",
    "\n",
    "for col in MissingServicesList:\n",
    "    TestCategoriesData[col] = 0\n",
    "\n",
    "TestCategoriesData.shape\n",
    "# Joing the encoded data to original dataframe \n",
    "NewTrainingData=traindata.join(TrainCategoriesData)\n",
    "NewTrainingData.drop('flag', axis=1, inplace=True)\n",
    "NewTrainingData.drop('protocol_type', axis=1, inplace=True)\n",
    "NewTrainingData.drop('service', axis=1, inplace=True)\n",
    "# Perform Same action on Test data\n",
    "NewTestData=testdata.join(TestCategoriesData)\n",
    "NewTestData.drop('flag', axis=1, inplace=True)\n",
    "NewTestData.drop('protocol_type', axis=1, inplace=True)\n",
    "NewTestData.drop('service', axis=1, inplace=True)\n",
    "print(NewTrainingData.shape)\n",
    "print(NewTestData.shape)\n",
    "display(HTML(tabulate.tabulate(NewTrainingData.head(), tablefmt='html')))\n",
    "        \n",
    "display(HTML(tabulate.tabulate(NewTestData.head(), tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-a92c7e6199b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNewTrainingData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'density'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2627\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   2628\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   1867\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1869\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_legend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_make_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             artists = self._plot(ax, y, column_num=i,\n\u001b[0;32m-> 1325\u001b[0;31m                                  stacking_id=stacking_id, **kwds)\n\u001b[0m\u001b[1;32m   1326\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_legend_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(cls, ax, y, style, bw_method, ind, column_num, stacking_id, **kwds)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m'0.11.0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0mgkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mgkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m             self._data_covariance = atleast_2d(np.cov(self.dataset, rowvar=1,\n\u001b[1;32m    509\u001b[0m                                                bias=False))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "NewTrainingData.plot(kind='density', subplots=True, layout=(12,12), sharex=False)\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">491</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\"> 2</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">150</td><td style=\"text-align: right;\"> 25</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">20</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">146</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 13</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.08</td><td style=\"text-align: right;\">0.15</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.6 </td><td style=\"text-align: right;\">0.88</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">123</td><td style=\"text-align: right;\"> 6</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">0.07</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\"> 26</td><td style=\"text-align: right;\">0.1 </td><td style=\"text-align: right;\">0.05</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">19</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">232</td><td style=\"text-align: right;\">8153</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  5</td><td style=\"text-align: right;\"> 5</td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\"> 30</td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">199</td><td style=\"text-align: right;\"> 420</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 30</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.09</td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">229</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">136</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">0.01</td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">255</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.06</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">12983</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">134</td><td style=\"text-align: right;\">86</td><td style=\"text-align: right;\">0.61</td><td style=\"text-align: right;\">0.04</td><td style=\"text-align: right;\">0.61</td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">21</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\"> 0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">65</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">57</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0.28</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 8</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.12</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">1   </td><td style=\"text-align: right;\">0   </td><td style=\"text-align: right;\">0.75</td><td style=\"text-align: right;\"> 29</td><td style=\"text-align: right;\">86</td><td style=\"text-align: right;\">0.31</td><td style=\"text-align: right;\">0.17</td><td style=\"text-align: right;\">0.03</td><td style=\"text-align: right;\">0.02</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.83</td><td style=\"text-align: right;\">0.71</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">11</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~End Of Data Prep~~~\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Label Encoding manually to make sure the conversions happens correctly\n",
    "# take label column from train Test Dataset\n",
    "LabelColVal=NewTrainingData['labels']\n",
    "TestLabelColVal=NewTestData['labels']\n",
    "# change the label column for train, test dataset\n",
    "NewLabelColVal=LabelColVal.replace({ 'normal' : 0, 'attack' : 1})\n",
    "NewTestLabelColVal=TestLabelColVal.replace({ 'normal' : 0, 'attack' : 1})\n",
    "# put the new label column back\n",
    "NewTrainingData['labels'] = NewLabelColVal\n",
    "NewTestData['labels'] = NewTestLabelColVal\n",
    "\n",
    "display(HTML(tabulate.tabulate(NewTrainingData.head(), tablefmt='html')))\n",
    "        \n",
    "display(HTML(tabulate.tabulate(NewTestData.head(), tablefmt='html')))\n",
    "\n",
    "X = NewTrainingData.iloc[:,1:124]\n",
    "Y = NewTrainingData.iloc[:,0]\n",
    "C = NewTestData.iloc[:,0]\n",
    "T = NewTestData.iloc[:,1:124]\n",
    "\n",
    "# Perform the split of the training data into Training and Validation data set\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "\n",
    "scalerXT = Normalizer().fit(X_train)\n",
    "trainX = scalerXT.transform(X_train)\n",
    "\n",
    "scalerXV = Normalizer().fit(X_validation)\n",
    "trainXV = scalerXV.transform(X_validation)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "Traindata = np.array(trainX)\n",
    "Trainlabel = np.array(Y_train)\n",
    "\n",
    "Validationdata = np.array(trainXV)\n",
    "Validationlabel = np.array(Y_validation)\n",
    "\n",
    "Testdata = np.array(testT)\n",
    "Testlabel = np.array(C)\n",
    "\n",
    "print(\"~~~End Of Data Prep~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Spot Check Algorithms\n",
    "ModelsList = []\n",
    "ModelsList.append(('LR', LogisticRegression()))\n",
    "ModelsList.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "ModelsList.append(('KNN', KNeighborsClassifier()))\n",
    "ModelsList.append(('CART', DecisionTreeClassifier()))\n",
    "ModelsList.append(('NB', GaussianNB()))\n",
    "ModelsList.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "ResultsList = []\n",
    "NamesOfModel = []\n",
    "for ModelName, Model in ModelsList:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    CrossValidationResults = model_selection.cross_val_score(Model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    ResultsList.append(CrossValidationResults)\n",
    "    NamesOfModel.append(ModelName)\n",
    "    msg = \"%s: %f (%f)\" % (ModelName, CrossValidationResults.mean(), CrossValidationResults.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM SVC Model\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Start Of SVM SVC model~~~~~~~~~~~~~~~~~~~\")\n",
    "clf = SVC(kernel='linear',class_weight=\"balanced\", max_iter=100000000)\n",
    "clf.fit(NewTrainingData, Trainlabel)\n",
    "clf_predict = clf.predict(NewTestData)\n",
    "print(clf.score(NewTestData, Testlabel))\n",
    "print(metrics.classification_report(Testlabel, clf_predict))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~End Of SVM SVC model~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~Start Of Naive Bayes model~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:236: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.PositiveTest)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.PositiveTest)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.TN + self.FP) * (self.TN + self.FN)))\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:332: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:191: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.P)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:276: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.P)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:346: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return(np.float64(self.LRP) / self.LRN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted      0    1   2   3    4   5    6   7  8  9   ...     20741  22174  \\\n",
      "Actual                                                  ...                    \n",
      "0          13576  166   4  28  174   7  675  43  0  0   ...         0      0   \n",
      "1            118    1   1   0    1   1    2   1  0  0   ...         0      0   \n",
      "2             62    0   4   0    0   0    2   0  0  0   ...         0      0   \n",
      "3             52    2   0   0    0   0    1   0  0  0   ...         0      0   \n",
      "4             13    0   0   0    0   1    5   0  0  0   ...         0      0   \n",
      "5             12    3   1   2    0   0   13   2  0  0   ...         0      0   \n",
      "6             11    0   0   0    0   0    0   1  0  0   ...         0      0   \n",
      "7              6    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "8              5    0   0   0    0   0    0   1  0  0   ...         0      0   \n",
      "9              3    0   1   0    0   0    0   0  0  0   ...         0      0   \n",
      "10             6    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "11             6    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "12             1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "13             2    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "14             0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "15             1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "16             0    0   0   0    0   0    1   0  0  0   ...         0      0   \n",
      "18             1    2   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "19             0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "20             1    9   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "21             0    4   0   0    0   1    0   0  0  0   ...         0      0   \n",
      "22             1    3   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "23             0    1   6   0    0   0    0   1  0  0   ...         0      0   \n",
      "24             0    0   1   0    0   0    0   0  0  0   ...         0      0   \n",
      "25             0    0   1   0    0   0    0   0  0  0   ...         0      0   \n",
      "26             3    0   3   0    0   0    0   1  0  0   ...         0      0   \n",
      "27             1    0   3   0    0   0    0   0  0  0   ...         0      0   \n",
      "28             1    0   5   0    0   0    0   0  0  0   ...         0      0   \n",
      "29             1    0   0   0    0   0    2   0  0  0   ...         0      0   \n",
      "30             2    0   2   0    0   0    0   0  0  0   ...         0      0   \n",
      "...          ...  ...  ..  ..  ...  ..  ...  .. .. ..   ...       ...    ...   \n",
      "8229           1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "8232           1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "8233           1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "8579           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "8625           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "8890           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "9535           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "9645           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "9741           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "10455          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "10499          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "11675          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "12112          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "12931          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "13067          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "13500          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "13919          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "16500          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "18848          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "20252          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "20741          0    0   0   0    1   0    0   0  0  0   ...         0      0   \n",
      "22174          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "38701          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "39930          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "42689          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "47114          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "53771          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "54451          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "57715          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
      "__all__    14418  686  36  31  195  11  723  50  0  0   ...         0      0   \n",
      "\n",
      "Predicted  38701  39930  42689  47114  53771  54451  57715  __all__  \n",
      "Actual                                                               \n",
      "0              0      0      0      0      0      0      0    19017  \n",
      "1              0      0      0      0      0      0      0      587  \n",
      "2              0      0      0      0      0      0      0      103  \n",
      "3              0      0      0      0      0      0      0      120  \n",
      "4              0      0      0      0      0      0      0      539  \n",
      "5              0      0      0      0      0      0      0      146  \n",
      "6              0      0      0      0      0      0      0       35  \n",
      "7              0      0      0      0      0      0      0       15  \n",
      "8              0      0      0      0      0      0      0       15  \n",
      "9              0      0      0      0      0      0      0       12  \n",
      "10             0      0      0      0      0      0      0       15  \n",
      "11             0      0      0      0      0      0      0        9  \n",
      "12             0      0      0      0      0      0      0        3  \n",
      "13             0      0      0      0      0      0      0        3  \n",
      "14             0      0      0      0      0      0      0        4  \n",
      "15             0      0      0      0      0      0      0        3  \n",
      "16             0      0      0      0      0      0      0        1  \n",
      "18             0      0      0      0      0      0      0        3  \n",
      "19             0      0      0      0      0      0      0        1  \n",
      "20             0      0      0      0      0      0      0       12  \n",
      "21             0      0      0      0      0      0      0        6  \n",
      "22             0      0      0      0      0      0      0        6  \n",
      "23             0      0      0      0      0      0      0       10  \n",
      "24             0      0      0      0      0      0      0        1  \n",
      "25             0      0      0      0      0      0      0        1  \n",
      "26             0      0      0      0      0      0      0        8  \n",
      "27             0      0      0      0      0      0      0        4  \n",
      "28             0      0      0      0      0      0      0        7  \n",
      "29             0      0      0      0      0      0      0        3  \n",
      "30             0      0      0      0      0      0      0        5  \n",
      "...          ...    ...    ...    ...    ...    ...    ...      ...  \n",
      "8229           0      0      0      0      0      0      0        1  \n",
      "8232           0      0      0      0      0      0      0        1  \n",
      "8233           0      0      0      0      0      0      0        1  \n",
      "8579           0      0      0      0      0      0      0        1  \n",
      "8625           0      0      0      0      0      0      0        0  \n",
      "8890           0      0      0      0      0      0      0        1  \n",
      "9535           0      0      0      0      0      0      0        0  \n",
      "9645           0      0      0      0      0      0      0        1  \n",
      "9741           0      0      0      0      0      0      0        0  \n",
      "10455          0      0      0      0      0      0      0        0  \n",
      "10499          0      0      0      0      0      0      0        1  \n",
      "11675          0      0      0      0      0      0      0        1  \n",
      "12112          0      0      0      0      0      0      0        1  \n",
      "12931          0      0      0      0      0      0      0        1  \n",
      "13067          0      0      0      0      0      0      0        1  \n",
      "13500          0      0      0      0      0      0      0        0  \n",
      "13919          0      0      0      0      0      0      0        0  \n",
      "16500          0      0      0      0      0      0      0        1  \n",
      "18848          0      0      0      0      0      0      0        0  \n",
      "20252          0      0      0      0      0      0      0        0  \n",
      "20741          0      0      0      0      0      0      0        1  \n",
      "22174          0      0      0      0      0      0      0        1  \n",
      "38701          0      0      0      0      0      0      0        1  \n",
      "39930          0      0      0      0      0      0      0        0  \n",
      "42689          0      0      0      0      0      0      0        1  \n",
      "47114          0      0      0      0      0      0      0        1  \n",
      "53771          0      0      0      0      0      0      0        1  \n",
      "54451          0      0      0      0      0      0      0        1  \n",
      "57715          0      0      0      0      0      0      0        1  \n",
      "__all__        0      1      0      0      0      0      0    22543  \n",
      "\n",
      "[665 rows x 665 columns]\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.602581732689\n",
      "95% CI: (0.59615852470164288, 0.60897848017185874)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.134691753753\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                    0           1           2      \\\n",
      "Population                                 22543       22543       22543   \n",
      "P: Condition positive                      19017         587         103   \n",
      "N: Condition negative                       3526       21956       22440   \n",
      "Test outcome positive                      14418         686          36   \n",
      "Test outcome negative                       8125       21857       22507   \n",
      "TP: True Positive                          13576           1           4   \n",
      "TN: True Negative                           2684       21271       22408   \n",
      "FP: False Positive                           842         685          32   \n",
      "FN: False Negative                          5441         586          99   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.713888  0.00170358    0.038835   \n",
      "TNR=SPC: (Specificity)                  0.761202    0.968801    0.998574   \n",
      "PPV: Pos Pred Value (Precision)         0.941601  0.00145773    0.111111   \n",
      "NPV: Neg Pred Value                     0.330338    0.973189    0.995601   \n",
      "FPR: False-out                          0.238798   0.0311988  0.00142602   \n",
      "FDR: False Discovery Rate              0.0583992    0.998542    0.888889   \n",
      "FNR: Miss Rate                          0.286112    0.998296    0.961165   \n",
      "ACC: Accuracy                           0.721288    0.943619    0.994189   \n",
      "F1 score                                0.812083  0.00157109    0.057554   \n",
      "MCC: Matthews correlation coefficient   0.359438  -0.0273457   0.0631823   \n",
      "Informedness                             0.47509  -0.0294952   0.0374089   \n",
      "Markedness                              0.271939  -0.0253529    0.106712   \n",
      "Prevalence                              0.843588   0.0260391  0.00456905   \n",
      "LR+: Positive likelihood ratio           2.98951    0.054604      27.233   \n",
      "LR-: Negative likelihood ratio          0.375869     1.03045    0.962538   \n",
      "DOR: Diagnostic odds ratio                7.9536   0.0529907     28.2929   \n",
      "FOR: False omission rate                0.669662   0.0268106  0.00439863   \n",
      "\n",
      "Classes                                     3           4            5      \\\n",
      "Population                                  22543       22543        22543   \n",
      "P: Condition positive                         120         539          146   \n",
      "N: Condition negative                       22423       22004        22397   \n",
      "Test outcome positive                          31         195           11   \n",
      "Test outcome negative                       22512       22348        22532   \n",
      "TP: True Positive                               0           0            0   \n",
      "TN: True Negative                           22392       21809        22386   \n",
      "FP: False Positive                             31         195           11   \n",
      "FN: False Negative                            120         539          146   \n",
      "TPR: (Sensitivity, hit rate, recall)            0           0            0   \n",
      "TNR=SPC: (Specificity)                   0.998617    0.991138     0.999509   \n",
      "PPV: Pos Pred Value (Precision)                 0           0            0   \n",
      "NPV: Neg Pred Value                       0.99467    0.975882      0.99352   \n",
      "FPR: False-out                         0.00138251  0.00886203  0.000491137   \n",
      "FDR: False Discovery Rate                       1           1            1   \n",
      "FNR: Miss Rate                                  1           1            1   \n",
      "ACC: Accuracy                            0.993302     0.96744     0.993036   \n",
      "F1 score                                        0           0            0   \n",
      "MCC: Matthews correlation coefficient -0.00271467  -0.0146198  -0.00178393   \n",
      "Informedness                          -0.00138251 -0.00886203 -0.000491137   \n",
      "Markedness                            -0.00533049  -0.0241185  -0.00647967   \n",
      "Prevalence                             0.00532316   0.0239099   0.00647651   \n",
      "LR+: Positive likelihood ratio                  0           0            0   \n",
      "LR-: Negative likelihood ratio            1.00138     1.00894      1.00049   \n",
      "DOR: Diagnostic odds ratio                      0           0            0   \n",
      "FOR: False omission rate               0.00533049   0.0241185   0.00647967   \n",
      "\n",
      "Classes                                     6            7            8      \\\n",
      "Population                                  22543        22543        22543   \n",
      "P: Condition positive                          35           15           15   \n",
      "N: Condition negative                       22508        22528        22528   \n",
      "Test outcome positive                         723           50            0   \n",
      "Test outcome negative                       21820        22493        22543   \n",
      "TP: True Positive                               0            0            0   \n",
      "TN: True Negative                           21785        22478        22528   \n",
      "FP: False Positive                            723           50            0   \n",
      "FN: False Negative                             35           15           15   \n",
      "TPR: (Sensitivity, hit rate, recall)            0            0            0   \n",
      "TNR=SPC: (Specificity)                   0.967878     0.997781            1   \n",
      "PPV: Pos Pred Value (Precision)                 0            0          NaN   \n",
      "NPV: Neg Pred Value                      0.998396     0.999333     0.999335   \n",
      "FPR: False-out                          0.0321219   0.00221946            0   \n",
      "FDR: False Discovery Rate                       1            1          NaN   \n",
      "FNR: Miss Rate                                  1            1            1   \n",
      "ACC: Accuracy                            0.966375     0.997117     0.999335   \n",
      "F1 score                                        0            0            0   \n",
      "MCC: Matthews correlation coefficient -0.00717806  -0.00121659          NaN   \n",
      "Informedness                           -0.0321219  -0.00221946            0   \n",
      "Markedness                            -0.00160403 -0.000666874          NaN   \n",
      "Prevalence                             0.00155259  0.000665395  0.000665395   \n",
      "LR+: Positive likelihood ratio                  0            0          NaN   \n",
      "LR-: Negative likelihood ratio            1.03319      1.00222            1   \n",
      "DOR: Diagnostic odds ratio                      0            0          NaN   \n",
      "FOR: False omission rate               0.00160403  0.000666874  0.000665395   \n",
      "\n",
      "Classes                                      9         ...            20252  \\\n",
      "Population                                   22543     ...            22543   \n",
      "P: Condition positive                           12     ...                0   \n",
      "N: Condition negative                        22531     ...            22543   \n",
      "Test outcome positive                            0     ...              218   \n",
      "Test outcome negative                        22543     ...            22325   \n",
      "TP: True Positive                                0     ...                0   \n",
      "TN: True Negative                            22531     ...            22325   \n",
      "FP: False Positive                               0     ...              218   \n",
      "FN: False Negative                              12     ...                0   \n",
      "TPR: (Sensitivity, hit rate, recall)             0     ...              NaN   \n",
      "TNR=SPC: (Specificity)                           1     ...          0.99033   \n",
      "PPV: Pos Pred Value (Precision)                NaN     ...                0   \n",
      "NPV: Neg Pred Value                       0.999468     ...                1   \n",
      "FPR: False-out                                   0     ...       0.00967041   \n",
      "FDR: False Discovery Rate                      NaN     ...                1   \n",
      "FNR: Miss Rate                                   1     ...              NaN   \n",
      "ACC: Accuracy                             0.999468     ...          0.99033   \n",
      "F1 score                                         0     ...                0   \n",
      "MCC: Matthews correlation coefficient          NaN     ...              NaN   \n",
      "Informedness                                     0     ...              NaN   \n",
      "Markedness                                     NaN     ...                0   \n",
      "Prevalence                             0.000532316     ...                0   \n",
      "LR+: Positive likelihood ratio                 NaN     ...              NaN   \n",
      "LR-: Negative likelihood ratio                   1     ...              NaN   \n",
      "DOR: Diagnostic odds ratio                     NaN     ...              NaN   \n",
      "FOR: False omission rate               0.000532316     ...                0   \n",
      "\n",
      "Classes                                      20741        22174        38701  \\\n",
      "Population                                   22543        22543        22543   \n",
      "P: Condition positive                            1            1            1   \n",
      "N: Condition negative                        22542        22542        22542   \n",
      "Test outcome positive                            0            0            0   \n",
      "Test outcome negative                        22543        22543        22543   \n",
      "TP: True Positive                                0            0            0   \n",
      "TN: True Negative                            22542        22542        22542   \n",
      "FP: False Positive                               0            0            0   \n",
      "FN: False Negative                               1            1            1   \n",
      "TPR: (Sensitivity, hit rate, recall)             0            0            0   \n",
      "TNR=SPC: (Specificity)                           1            1            1   \n",
      "PPV: Pos Pred Value (Precision)                NaN          NaN          NaN   \n",
      "NPV: Neg Pred Value                       0.999956     0.999956     0.999956   \n",
      "FPR: False-out                                   0            0            0   \n",
      "FDR: False Discovery Rate                      NaN          NaN          NaN   \n",
      "FNR: Miss Rate                                   1            1            1   \n",
      "ACC: Accuracy                             0.999956     0.999956     0.999956   \n",
      "F1 score                                         0            0            0   \n",
      "MCC: Matthews correlation coefficient          NaN          NaN          NaN   \n",
      "Informedness                                     0            0            0   \n",
      "Markedness                                     NaN          NaN          NaN   \n",
      "Prevalence                             4.43597e-05  4.43597e-05  4.43597e-05   \n",
      "LR+: Positive likelihood ratio                 NaN          NaN          NaN   \n",
      "LR-: Negative likelihood ratio                   1            1            1   \n",
      "DOR: Diagnostic odds ratio                     NaN          NaN          NaN   \n",
      "FOR: False omission rate               4.43597e-05  4.43597e-05  4.43597e-05   \n",
      "\n",
      "Classes                                      39930        42689        47114  \\\n",
      "Population                                   22543        22543        22543   \n",
      "P: Condition positive                            0            1            1   \n",
      "N: Condition negative                        22543        22542        22542   \n",
      "Test outcome positive                            1            0            0   \n",
      "Test outcome negative                        22542        22543        22543   \n",
      "TP: True Positive                                0            0            0   \n",
      "TN: True Negative                            22542        22542        22542   \n",
      "FP: False Positive                               1            0            0   \n",
      "FN: False Negative                               0            1            1   \n",
      "TPR: (Sensitivity, hit rate, recall)           NaN            0            0   \n",
      "TNR=SPC: (Specificity)                    0.999956            1            1   \n",
      "PPV: Pos Pred Value (Precision)                  0          NaN          NaN   \n",
      "NPV: Neg Pred Value                              1     0.999956     0.999956   \n",
      "FPR: False-out                         4.43597e-05            0            0   \n",
      "FDR: False Discovery Rate                        1          NaN          NaN   \n",
      "FNR: Miss Rate                                 NaN            1            1   \n",
      "ACC: Accuracy                             0.999956     0.999956     0.999956   \n",
      "F1 score                                         0            0            0   \n",
      "MCC: Matthews correlation coefficient          NaN          NaN          NaN   \n",
      "Informedness                                   NaN            0            0   \n",
      "Markedness                                       0          NaN          NaN   \n",
      "Prevalence                                       0  4.43597e-05  4.43597e-05   \n",
      "LR+: Positive likelihood ratio                 NaN          NaN          NaN   \n",
      "LR-: Negative likelihood ratio                 NaN            1            1   \n",
      "DOR: Diagnostic odds ratio                     NaN          NaN          NaN   \n",
      "FOR: False omission rate                         0  4.43597e-05  4.43597e-05   \n",
      "\n",
      "Classes                                      53771        54451        57715  \n",
      "Population                                   22543        22543        22543  \n",
      "P: Condition positive                            1            1            1  \n",
      "N: Condition negative                        22542        22542        22542  \n",
      "Test outcome positive                            0            0            0  \n",
      "Test outcome negative                        22543        22543        22543  \n",
      "TP: True Positive                                0            0            0  \n",
      "TN: True Negative                            22542        22542        22542  \n",
      "FP: False Positive                               0            0            0  \n",
      "FN: False Negative                               1            1            1  \n",
      "TPR: (Sensitivity, hit rate, recall)             0            0            0  \n",
      "TNR=SPC: (Specificity)                           1            1            1  \n",
      "PPV: Pos Pred Value (Precision)                NaN          NaN          NaN  \n",
      "NPV: Neg Pred Value                       0.999956     0.999956     0.999956  \n",
      "FPR: False-out                                   0            0            0  \n",
      "FDR: False Discovery Rate                      NaN          NaN          NaN  \n",
      "FNR: Miss Rate                                   1            1            1  \n",
      "ACC: Accuracy                             0.999956     0.999956     0.999956  \n",
      "F1 score                                         0            0            0  \n",
      "MCC: Matthews correlation coefficient          NaN          NaN          NaN  \n",
      "Informedness                                     0            0            0  \n",
      "Markedness                                     NaN          NaN          NaN  \n",
      "Prevalence                             4.43597e-05  4.43597e-05  4.43597e-05  \n",
      "LR+: Positive likelihood ratio                 NaN          NaN          NaN  \n",
      "LR-: Negative likelihood ratio                   1            1            1  \n",
      "DOR: Diagnostic odds ratio                     NaN          NaN          NaN  \n",
      "FOR: False omission rate               4.43597e-05  4.43597e-05  4.43597e-05  \n",
      "\n",
      "[26 rows x 664 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted      0    1   2   3    4   5    6   7  8  9   ...     20741  22174  \\\n",
       "Actual                                                  ...                    \n",
       "0          13576  166   4  28  174   7  675  43  0  0   ...         0      0   \n",
       "1            118    1   1   0    1   1    2   1  0  0   ...         0      0   \n",
       "2             62    0   4   0    0   0    2   0  0  0   ...         0      0   \n",
       "3             52    2   0   0    0   0    1   0  0  0   ...         0      0   \n",
       "4             13    0   0   0    0   1    5   0  0  0   ...         0      0   \n",
       "5             12    3   1   2    0   0   13   2  0  0   ...         0      0   \n",
       "6             11    0   0   0    0   0    0   1  0  0   ...         0      0   \n",
       "7              6    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "8              5    0   0   0    0   0    0   1  0  0   ...         0      0   \n",
       "9              3    0   1   0    0   0    0   0  0  0   ...         0      0   \n",
       "10             6    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "11             6    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "12             1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "13             2    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "14             0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "15             1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "16             0    0   0   0    0   0    1   0  0  0   ...         0      0   \n",
       "18             1    2   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "19             0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "20             1    9   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "21             0    4   0   0    0   1    0   0  0  0   ...         0      0   \n",
       "22             1    3   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "23             0    1   6   0    0   0    0   1  0  0   ...         0      0   \n",
       "24             0    0   1   0    0   0    0   0  0  0   ...         0      0   \n",
       "25             0    0   1   0    0   0    0   0  0  0   ...         0      0   \n",
       "26             3    0   3   0    0   0    0   1  0  0   ...         0      0   \n",
       "27             1    0   3   0    0   0    0   0  0  0   ...         0      0   \n",
       "28             1    0   5   0    0   0    0   0  0  0   ...         0      0   \n",
       "29             1    0   0   0    0   0    2   0  0  0   ...         0      0   \n",
       "30             2    0   2   0    0   0    0   0  0  0   ...         0      0   \n",
       "...          ...  ...  ..  ..  ...  ..  ...  .. .. ..   ...       ...    ...   \n",
       "8229           1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "8232           1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "8233           1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "8579           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "8625           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "8890           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "9535           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "9645           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "9741           0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "10455          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "10499          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "11675          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "12112          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "12931          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "13067          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "13500          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "13919          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "16500          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "18848          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "20252          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "20741          0    0   0   0    1   0    0   0  0  0   ...         0      0   \n",
       "22174          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "38701          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "39930          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "42689          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "47114          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "53771          1    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "54451          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "57715          0    0   0   0    0   0    0   0  0  0   ...         0      0   \n",
       "__all__    14418  686  36  31  195  11  723  50  0  0   ...         0      0   \n",
       "\n",
       "Predicted  38701  39930  42689  47114  53771  54451  57715  __all__  \n",
       "Actual                                                               \n",
       "0              0      0      0      0      0      0      0    19017  \n",
       "1              0      0      0      0      0      0      0      587  \n",
       "2              0      0      0      0      0      0      0      103  \n",
       "3              0      0      0      0      0      0      0      120  \n",
       "4              0      0      0      0      0      0      0      539  \n",
       "5              0      0      0      0      0      0      0      146  \n",
       "6              0      0      0      0      0      0      0       35  \n",
       "7              0      0      0      0      0      0      0       15  \n",
       "8              0      0      0      0      0      0      0       15  \n",
       "9              0      0      0      0      0      0      0       12  \n",
       "10             0      0      0      0      0      0      0       15  \n",
       "11             0      0      0      0      0      0      0        9  \n",
       "12             0      0      0      0      0      0      0        3  \n",
       "13             0      0      0      0      0      0      0        3  \n",
       "14             0      0      0      0      0      0      0        4  \n",
       "15             0      0      0      0      0      0      0        3  \n",
       "16             0      0      0      0      0      0      0        1  \n",
       "18             0      0      0      0      0      0      0        3  \n",
       "19             0      0      0      0      0      0      0        1  \n",
       "20             0      0      0      0      0      0      0       12  \n",
       "21             0      0      0      0      0      0      0        6  \n",
       "22             0      0      0      0      0      0      0        6  \n",
       "23             0      0      0      0      0      0      0       10  \n",
       "24             0      0      0      0      0      0      0        1  \n",
       "25             0      0      0      0      0      0      0        1  \n",
       "26             0      0      0      0      0      0      0        8  \n",
       "27             0      0      0      0      0      0      0        4  \n",
       "28             0      0      0      0      0      0      0        7  \n",
       "29             0      0      0      0      0      0      0        3  \n",
       "30             0      0      0      0      0      0      0        5  \n",
       "...          ...    ...    ...    ...    ...    ...    ...      ...  \n",
       "8229           0      0      0      0      0      0      0        1  \n",
       "8232           0      0      0      0      0      0      0        1  \n",
       "8233           0      0      0      0      0      0      0        1  \n",
       "8579           0      0      0      0      0      0      0        1  \n",
       "8625           0      0      0      0      0      0      0        0  \n",
       "8890           0      0      0      0      0      0      0        1  \n",
       "9535           0      0      0      0      0      0      0        0  \n",
       "9645           0      0      0      0      0      0      0        1  \n",
       "9741           0      0      0      0      0      0      0        0  \n",
       "10455          0      0      0      0      0      0      0        0  \n",
       "10499          0      0      0      0      0      0      0        1  \n",
       "11675          0      0      0      0      0      0      0        1  \n",
       "12112          0      0      0      0      0      0      0        1  \n",
       "12931          0      0      0      0      0      0      0        1  \n",
       "13067          0      0      0      0      0      0      0        1  \n",
       "13500          0      0      0      0      0      0      0        0  \n",
       "13919          0      0      0      0      0      0      0        0  \n",
       "16500          0      0      0      0      0      0      0        1  \n",
       "18848          0      0      0      0      0      0      0        0  \n",
       "20252          0      0      0      0      0      0      0        0  \n",
       "20741          0      0      0      0      0      0      0        1  \n",
       "22174          0      0      0      0      0      0      0        1  \n",
       "38701          0      0      0      0      0      0      0        1  \n",
       "39930          0      0      0      0      0      0      0        0  \n",
       "42689          0      0      0      0      0      0      0        1  \n",
       "47114          0      0      0      0      0      0      0        1  \n",
       "53771          0      0      0      0      0      0      0        1  \n",
       "54451          0      0      0      0      0      0      0        1  \n",
       "57715          0      0      0      0      0      0      0        1  \n",
       "__all__        0      1      0      0      0      0      0    22543  \n",
       "\n",
       "[665 rows x 665 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Naive Bayes model PredictedResults Shape: '(22543,)'</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Naive Bayes model ExpectedResults Shape: '(22543,)'</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Accuracy</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.603"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>precision</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.795"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>recall</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.603"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.685"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~End Of Naive Bayes model~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print(\"~~~~~~~~~~~~~~~~~~~Start Of Naive Bayes model~~~~~~~~~~~~~~~~~~~\")\n",
    "# fit a Naive Bayes model to the data\n",
    "GNBmodel = GaussianNB()\n",
    "GNBmodel.fit(Traindata, Trainlabel)\n",
    "display(GNBmodel)\n",
    "# make predictions\n",
    "GNBexpected = Testlabel\n",
    "GNBpredicted = GNBmodel.predict(Testdata)\n",
    "\n",
    "GNBcm = ConfusionMatrix(GNBexpected, GNBpredicted)\n",
    "#display(GNBexpected.shape)\n",
    "#display(GNBpredicted.shape)\n",
    "GNBexpected = np.array(GNBexpected)\n",
    "predicted = np.array(GNBpredicted)\n",
    "GNBcm.print_stats()\n",
    "\n",
    "np.savetxt('GNBexpected.txt', GNBexpected, fmt='%01d')\n",
    "np.savetxt('GNBpredicted.txt', GNBpredicted , fmt='%01d')\n",
    "\n",
    "display(GNBcm)\n",
    "display(HTML(\"<h4> Naive Bayes model PredictedResults Shape: '{GNBP}'</h4>\".\n",
    "                     format(ColumnName=ColumnName, GNBP=GNBexpected.shape))) #GNBexpected.shape)\n",
    "display(HTML(\"<h4> Naive Bayes model ExpectedResults Shape: '{GNBE}'</h4>\".\n",
    "                     format(ColumnName=ColumnName, GNBE=GNBpredicted.shape)))\n",
    "#display(GNBpredicted.shape)\n",
    "GNBcm.stats()\n",
    "\n",
    "GNBaccuracy = accuracy_score(GNBexpected, GNBpredicted)\n",
    "GNBprecision = precision_score(GNBexpected, GNBpredicted, average='weighted')\n",
    "GNBrecall = recall_score(GNBexpected, GNBpredicted, average='weighted')\n",
    "GNBf1 = 2 * (GNBprecision * GNBrecall) / (GNBprecision + GNBrecall)\n",
    "\n",
    "display(HTML(\"<h3>Accuracy</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', GNBaccuracy)))\n",
    "\n",
    "display(HTML(\"<h3>precision</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', GNBprecision))) \n",
    "\n",
    "display(HTML(\"<h3>recall</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', GNBrecall)))\n",
    "\n",
    "display(HTML(\"<h3>f1-score</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', GNBf1)))\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~End Of Naive Bayes model~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~Start Of k-nearest neighbor model~~~~~~~~~~~~~~~~~~~\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "[[18853    70    10 ...,     0     0     0]\n",
      " [  551    25     4 ...,     0     0     0]\n",
      " [   97     4     0 ...,     0     0     0]\n",
      " ..., \n",
      " [    0     0     0 ...,     0     0     0]\n",
      " [    1     0     0 ...,     0     0     0]\n",
      " [    0     0     0 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Accuracy</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.838"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>precision</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.730"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>recall</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.838"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.781"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.043"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.991"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~End Of k-nearest neighbor model~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Start Of k-nearest neighbor model~~~~~~~~~~~~~~~~~~~\")\n",
    "# fit a k-nearest neighbor model to the data\n",
    "KNmodel = KNeighborsClassifier()\n",
    "KNmodel.fit(Traindata, Trainlabel)\n",
    "print(KNmodel)\n",
    "# make predictions\n",
    "KNexpected = Testlabel\n",
    "KNpredicted = KNmodel.predict(Testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "KNcm = metrics.confusion_matrix(KNexpected, KNpredicted)\n",
    "print(KNcm)\n",
    "KNtpr = float(KNcm[0][0])/np.sum(KNcm[0])\n",
    "KNfpr = float(KNcm[1][1])/np.sum(KNcm[1])\n",
    "KNaccuracy = accuracy_score(KNexpected, KNpredicted)\n",
    "KNprecision = precision_score(KNexpected, KNpredicted, average='weighted')\n",
    "KNrecall = recall_score(KNexpected, KNpredicted, average='weighted')\n",
    "KNf1 = 2 * (KNprecision * KNrecall) / (KNprecision + KNrecall)\n",
    "\n",
    "display(HTML(\"<h3>Accuracy</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', KNaccuracy)))\n",
    "\n",
    "display(HTML(\"<h3>precision</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', KNprecision))) \n",
    "\n",
    "display(HTML(\"<h3>recall</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', KNrecall)))\n",
    "\n",
    "display(HTML(\"<h3>f-score</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', KNf1)))\n",
    "\n",
    "display(HTML(\"<h3>FPR</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', KNfpr)))\n",
    "\n",
    "display(HTML(\"<h3>TPR</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', KNtpr)))\n",
    "\n",
    "np.savetxt('KNexpected.txt', KNexpected, fmt='%01d')\n",
    "np.savetxt('KNpredicted.txt', KNpredicted, fmt='%01d')\n",
    "print(\"~~~~~~~~~~~~~~~~~~~End Of k-nearest neighbor model~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~Start Of Decision Tree model~~~~~~~~~~~~~~~~~~~\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "[[17771   203   150 ...,     0     0     0]\n",
      " [  538     0    27 ...,     0     0     0]\n",
      " [   80     0    14 ...,     0     0     0]\n",
      " ..., \n",
      " [    1     0     0 ...,     0     0     0]\n",
      " [    1     0     0 ...,     0     0     0]\n",
      " [    0     0     0 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Accuracy</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.789"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>precision</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.736"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>recall</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.789"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.761"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>FPR</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.000"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>TPR</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.934"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~End Of Decision Tree model~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Start Of Decision Tree model~~~~~~~~~~~~~~~~~~~\")\n",
    "# fit a Decision Tree model to the data\n",
    "DTmodel = DecisionTreeClassifier()\n",
    "DTmodel.fit(Traindata, Trainlabel)\n",
    "print(DTmodel)\n",
    "\n",
    "# make predictions\n",
    "DTexpected = Testlabel\n",
    "DTpredicted = DTmodel.predict(Testdata)\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "DTcm = metrics.confusion_matrix(DTexpected, DTpredicted)\n",
    "print(DTcm)\n",
    "DTtpr = float(DTcm[0][0])/np.sum(DTcm[0])\n",
    "DTfpr = float(DTcm[1][1])/np.sum(DTcm[1])\n",
    "DTaccuracy = accuracy_score(DTexpected, DTpredicted)\n",
    "DTprecision = precision_score(DTexpected, DTpredicted, average='weighted')\n",
    "DTrecall = recall_score(DTexpected, DTpredicted, average='weighted')\n",
    "DTf1 = 2 * (DTprecision * DTrecall) / (DTprecision + DTrecall)\n",
    "\n",
    "display(HTML(\"<h3>Accuracy</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', DTaccuracy)))\n",
    "\n",
    "display(HTML(\"<h3>precision</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', DTprecision))) \n",
    "\n",
    "display(HTML(\"<h3>recall</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', DTrecall)))\n",
    "\n",
    "display(HTML(\"<h3>f-score</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', DTf1)))\n",
    "\n",
    "display(HTML(\"<h3>FPR</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', DTfpr)))\n",
    "\n",
    "display(HTML(\"<h3>TPR</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', DTtpr)))\n",
    "\n",
    "np.savetxt('DTexpected.txt', DTexpected, fmt='%01d')\n",
    "np.savetxt('DTpredicted.txt', DTpredicted, fmt='%01d')\n",
    "print(\"~~~~~~~~~~~~~~~~~~~End Of Decision Tree model~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~Start Of Random Forest model~~~~~~~~~~~~~~~~~~~\n",
      "[[19017     0     0 ...,     0     0     0]\n",
      " [  587     0     0 ...,     0     0     0]\n",
      " [  103     0     0 ...,     0     0     0]\n",
      " ..., \n",
      " [    1     0     0 ...,     0     0     0]\n",
      " [    1     0     0 ...,     0     0     0]\n",
      " [    1     0     0 ...,     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Accuracy</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.844"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>precision</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.712"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>recall</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.844"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.772"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>FPR</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.000"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>TPR</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.000"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~End Of Random Forest model~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~Start Of Random Forest model~~~~~~~~~~~~~~~~~~~\")\n",
    "# fit a Random Forest model to the data\n",
    "RFmodel = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=20)\n",
    "RFmodel = RFmodel.fit(Traindata, Trainlabel)\n",
    "\n",
    "# make predictions\n",
    "RFexpected = Testlabel\n",
    "RFpredicted = RFmodel.predict(Testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "RFcm = metrics.confusion_matrix(RFexpected, RFpredicted)\n",
    "print(RFcm)\n",
    "RFtpr = float(RFcm[0][0])/np.sum(RFcm[0])\n",
    "RFfpr = float(RFcm[1][1])/np.sum(RFcm[1])\n",
    "RFaccuracy = accuracy_score(RFexpected, RFpredicted)\n",
    "RFprecision = precision_score(RFexpected, RFpredicted, average='weighted')\n",
    "RFrecall = recall_score(RFexpected, RFpredicted, average='weighted')\n",
    "RFf1 = 2 * (RFprecision * RFrecall) / (RFprecision + RFrecall)\n",
    "\n",
    "display(HTML(\"<h3>Accuracy</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', RFaccuracy)))\n",
    "\n",
    "display(HTML(\"<h3>precision</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', RFprecision))) \n",
    "\n",
    "display(HTML(\"<h3>recall</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', RFrecall)))\n",
    "\n",
    "display(HTML(\"<h3>f-score</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', RFf1)))\n",
    "\n",
    "display(HTML(\"<h3>FPR</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', RFfpr)))\n",
    "\n",
    "display(HTML(\"<h3>TPR</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', RFtpr)))\n",
    "#print(\"%.3f\" %RFtpr)\n",
    "#print(\"%.3f\" %RFfpr)\n",
    "#print(\"Accuracy\")\n",
    "#print(\"%.3f\" %RFaccuracy)\n",
    "#print(\"precision\")\n",
    "#print(\"%.3f\" %RFprecision)\n",
    "#print(\"recall\")\n",
    "#print(\"%.3f\" %RFrecall)\n",
    "#print(\"f-score\")\n",
    "#print(\"%.3f\" %RFf1)\n",
    "#print(\"fpr\")\n",
    "#print(\"%.3f\" %RFfpr)\n",
    "#print(\"tpr\")\n",
    "#print(\"%.3f\" %RFtpr)\n",
    "np.savetxt('RFexpected.txt', RFexpected, fmt='%01d')\n",
    "np.savetxt('RFpredicted.txt', RFpredicted, fmt='%01d')\n",
    "print(\"~~~~~~~~~~~~~~~~~~~End Of Random Forest model~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~Start Of Multinomial Naive Bayes model~~~~~~~~~~~~~~~~~~~\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TN) / self.NegativeTest)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.TN + self.FP) * (self.TN + self.FN)))\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:339: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FNR) / self.TNR)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.NegativeTest)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:236: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.PositiveTest)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.PositiveTest)\n",
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:332: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted      0  1  2  3  4  5  6  7  8  9   ...     16500  20741  22174  \\\n",
      "Actual                                        ...                           \n",
      "0          19017  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "1            587  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "2            103  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "3            120  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "4            539  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "5            146  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "6             35  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "7             15  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8             15  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "9             12  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "10            15  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "11             9  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "12             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "13             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "14             4  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "15             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "16             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "18             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "19             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "20            12  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "21             6  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "22             6  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "23            10  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "24             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "25             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "26             8  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "27             4  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "28             7  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "29             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "30             5  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "...          ... .. .. .. .. .. .. .. .. ..   ...       ...    ...    ...   \n",
      "8209           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8212           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8213           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8216           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8217           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8220           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8221           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8224           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8228           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8229           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8232           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8233           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8579           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "8890           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "9645           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "10499          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "11675          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "12112          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "12931          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "13067          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "16500          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "20741          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "22174          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "38701          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "42689          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "47114          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "53771          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "54451          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "57715          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "__all__    22543  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
      "\n",
      "Predicted  38701  42689  47114  53771  54451  57715  __all__  \n",
      "Actual                                                        \n",
      "0              0      0      0      0      0      0    19017  \n",
      "1              0      0      0      0      0      0      587  \n",
      "2              0      0      0      0      0      0      103  \n",
      "3              0      0      0      0      0      0      120  \n",
      "4              0      0      0      0      0      0      539  \n",
      "5              0      0      0      0      0      0      146  \n",
      "6              0      0      0      0      0      0       35  \n",
      "7              0      0      0      0      0      0       15  \n",
      "8              0      0      0      0      0      0       15  \n",
      "9              0      0      0      0      0      0       12  \n",
      "10             0      0      0      0      0      0       15  \n",
      "11             0      0      0      0      0      0        9  \n",
      "12             0      0      0      0      0      0        3  \n",
      "13             0      0      0      0      0      0        3  \n",
      "14             0      0      0      0      0      0        4  \n",
      "15             0      0      0      0      0      0        3  \n",
      "16             0      0      0      0      0      0        1  \n",
      "18             0      0      0      0      0      0        3  \n",
      "19             0      0      0      0      0      0        1  \n",
      "20             0      0      0      0      0      0       12  \n",
      "21             0      0      0      0      0      0        6  \n",
      "22             0      0      0      0      0      0        6  \n",
      "23             0      0      0      0      0      0       10  \n",
      "24             0      0      0      0      0      0        1  \n",
      "25             0      0      0      0      0      0        1  \n",
      "26             0      0      0      0      0      0        8  \n",
      "27             0      0      0      0      0      0        4  \n",
      "28             0      0      0      0      0      0        7  \n",
      "29             0      0      0      0      0      0        3  \n",
      "30             0      0      0      0      0      0        5  \n",
      "...          ...    ...    ...    ...    ...    ...      ...  \n",
      "8209           0      0      0      0      0      0        1  \n",
      "8212           0      0      0      0      0      0        2  \n",
      "8213           0      0      0      0      0      0        1  \n",
      "8216           0      0      0      0      0      0        1  \n",
      "8217           0      0      0      0      0      0        1  \n",
      "8220           0      0      0      0      0      0        2  \n",
      "8221           0      0      0      0      0      0        1  \n",
      "8224           0      0      0      0      0      0        2  \n",
      "8228           0      0      0      0      0      0        2  \n",
      "8229           0      0      0      0      0      0        1  \n",
      "8232           0      0      0      0      0      0        1  \n",
      "8233           0      0      0      0      0      0        1  \n",
      "8579           0      0      0      0      0      0        1  \n",
      "8890           0      0      0      0      0      0        1  \n",
      "9645           0      0      0      0      0      0        1  \n",
      "10499          0      0      0      0      0      0        1  \n",
      "11675          0      0      0      0      0      0        1  \n",
      "12112          0      0      0      0      0      0        1  \n",
      "12931          0      0      0      0      0      0        1  \n",
      "13067          0      0      0      0      0      0        1  \n",
      "16500          0      0      0      0      0      0        1  \n",
      "20741          0      0      0      0      0      0        1  \n",
      "22174          0      0      0      0      0      0        1  \n",
      "38701          0      0      0      0      0      0        1  \n",
      "42689          0      0      0      0      0      0        1  \n",
      "47114          0      0      0      0      0      0        1  \n",
      "53771          0      0      0      0      0      0        1  \n",
      "54451          0      0      0      0      0      0        1  \n",
      "57715          0      0      0      0      0      0        1  \n",
      "__all__        0      0      0      0      0      0    22543  \n",
      "\n",
      "[625 rows x 625 columns]\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.843587809963\n",
      "95% CI: (0.83877958771245364, 0.84830726475481788)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.0\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                   0          1           2      \\\n",
      "Population                                22543      22543       22543   \n",
      "P: Condition positive                     19017        587         103   \n",
      "N: Condition negative                      3526      21956       22440   \n",
      "Test outcome positive                     22543          0           0   \n",
      "Test outcome negative                         0      22543       22543   \n",
      "TP: True Positive                         19017          0           0   \n",
      "TN: True Negative                             0      21956       22440   \n",
      "FP: False Positive                         3526          0           0   \n",
      "FN: False Negative                            0        587         103   \n",
      "TPR: (Sensitivity, hit rate, recall)          1          0           0   \n",
      "TNR=SPC: (Specificity)                        0          1           1   \n",
      "PPV: Pos Pred Value (Precision)        0.843588        NaN         NaN   \n",
      "NPV: Neg Pred Value                         NaN   0.973961    0.995431   \n",
      "FPR: False-out                                1          0           0   \n",
      "FDR: False Discovery Rate              0.156412        NaN         NaN   \n",
      "FNR: Miss Rate                                0          1           1   \n",
      "ACC: Accuracy                          0.843588   0.973961    0.995431   \n",
      "F1 score                               0.915159          0           0   \n",
      "MCC: Matthews correlation coefficient       NaN        NaN         NaN   \n",
      "Informedness                                  0          0           0   \n",
      "Markedness                                  NaN        NaN         NaN   \n",
      "Prevalence                             0.843588  0.0260391  0.00456905   \n",
      "LR+: Positive likelihood ratio                1        NaN         NaN   \n",
      "LR-: Negative likelihood ratio              NaN          1           1   \n",
      "DOR: Diagnostic odds ratio                  NaN        NaN         NaN   \n",
      "FOR: False omission rate                    NaN  0.0260391  0.00456905   \n",
      "\n",
      "Classes                                     3          4           5      \\\n",
      "Population                                  22543      22543       22543   \n",
      "P: Condition positive                         120        539         146   \n",
      "N: Condition negative                       22423      22004       22397   \n",
      "Test outcome positive                           0          0           0   \n",
      "Test outcome negative                       22543      22543       22543   \n",
      "TP: True Positive                               0          0           0   \n",
      "TN: True Negative                           22423      22004       22397   \n",
      "FP: False Positive                              0          0           0   \n",
      "FN: False Negative                            120        539         146   \n",
      "TPR: (Sensitivity, hit rate, recall)            0          0           0   \n",
      "TNR=SPC: (Specificity)                          1          1           1   \n",
      "PPV: Pos Pred Value (Precision)               NaN        NaN         NaN   \n",
      "NPV: Neg Pred Value                      0.994677    0.97609    0.993523   \n",
      "FPR: False-out                                  0          0           0   \n",
      "FDR: False Discovery Rate                     NaN        NaN         NaN   \n",
      "FNR: Miss Rate                                  1          1           1   \n",
      "ACC: Accuracy                            0.994677    0.97609    0.993523   \n",
      "F1 score                                        0          0           0   \n",
      "MCC: Matthews correlation coefficient         NaN        NaN         NaN   \n",
      "Informedness                                    0          0           0   \n",
      "Markedness                                    NaN        NaN         NaN   \n",
      "Prevalence                             0.00532316  0.0239099  0.00647651   \n",
      "LR+: Positive likelihood ratio                NaN        NaN         NaN   \n",
      "LR-: Negative likelihood ratio                  1          1           1   \n",
      "DOR: Diagnostic odds ratio                    NaN        NaN         NaN   \n",
      "FOR: False omission rate               0.00532316  0.0239099  0.00647651   \n",
      "\n",
      "Classes                                     6            7            8      \\\n",
      "Population                                  22543        22543        22543   \n",
      "P: Condition positive                          35           15           15   \n",
      "N: Condition negative                       22508        22528        22528   \n",
      "Test outcome positive                           0            0            0   \n",
      "Test outcome negative                       22543        22543        22543   \n",
      "TP: True Positive                               0            0            0   \n",
      "TN: True Negative                           22508        22528        22528   \n",
      "FP: False Positive                              0            0            0   \n",
      "FN: False Negative                             35           15           15   \n",
      "TPR: (Sensitivity, hit rate, recall)            0            0            0   \n",
      "TNR=SPC: (Specificity)                          1            1            1   \n",
      "PPV: Pos Pred Value (Precision)               NaN          NaN          NaN   \n",
      "NPV: Neg Pred Value                      0.998447     0.999335     0.999335   \n",
      "FPR: False-out                                  0            0            0   \n",
      "FDR: False Discovery Rate                     NaN          NaN          NaN   \n",
      "FNR: Miss Rate                                  1            1            1   \n",
      "ACC: Accuracy                            0.998447     0.999335     0.999335   \n",
      "F1 score                                        0            0            0   \n",
      "MCC: Matthews correlation coefficient         NaN          NaN          NaN   \n",
      "Informedness                                    0            0            0   \n",
      "Markedness                                    NaN          NaN          NaN   \n",
      "Prevalence                             0.00155259  0.000665395  0.000665395   \n",
      "LR+: Positive likelihood ratio                NaN          NaN          NaN   \n",
      "LR-: Negative likelihood ratio                  1            1            1   \n",
      "DOR: Diagnostic odds ratio                    NaN          NaN          NaN   \n",
      "FOR: False omission rate               0.00155259  0.000665395  0.000665395   \n",
      "\n",
      "Classes                                      9         ...             13067  \\\n",
      "Population                                   22543     ...             22543   \n",
      "P: Condition positive                           12     ...                 1   \n",
      "N: Condition negative                        22531     ...             22542   \n",
      "Test outcome positive                            0     ...                 0   \n",
      "Test outcome negative                        22543     ...             22543   \n",
      "TP: True Positive                                0     ...                 0   \n",
      "TN: True Negative                            22531     ...             22542   \n",
      "FP: False Positive                               0     ...                 0   \n",
      "FN: False Negative                              12     ...                 1   \n",
      "TPR: (Sensitivity, hit rate, recall)             0     ...                 0   \n",
      "TNR=SPC: (Specificity)                           1     ...                 1   \n",
      "PPV: Pos Pred Value (Precision)                NaN     ...               NaN   \n",
      "NPV: Neg Pred Value                       0.999468     ...          0.999956   \n",
      "FPR: False-out                                   0     ...                 0   \n",
      "FDR: False Discovery Rate                      NaN     ...               NaN   \n",
      "FNR: Miss Rate                                   1     ...                 1   \n",
      "ACC: Accuracy                             0.999468     ...          0.999956   \n",
      "F1 score                                         0     ...                 0   \n",
      "MCC: Matthews correlation coefficient          NaN     ...               NaN   \n",
      "Informedness                                     0     ...                 0   \n",
      "Markedness                                     NaN     ...               NaN   \n",
      "Prevalence                             0.000532316     ...       4.43597e-05   \n",
      "LR+: Positive likelihood ratio                 NaN     ...               NaN   \n",
      "LR-: Negative likelihood ratio                   1     ...                 1   \n",
      "DOR: Diagnostic odds ratio                     NaN     ...               NaN   \n",
      "FOR: False omission rate               0.000532316     ...       4.43597e-05   \n",
      "\n",
      "Classes                                      16500        20741        22174  \\\n",
      "Population                                   22543        22543        22543   \n",
      "P: Condition positive                            1            1            1   \n",
      "N: Condition negative                        22542        22542        22542   \n",
      "Test outcome positive                            0            0            0   \n",
      "Test outcome negative                        22543        22543        22543   \n",
      "TP: True Positive                                0            0            0   \n",
      "TN: True Negative                            22542        22542        22542   \n",
      "FP: False Positive                               0            0            0   \n",
      "FN: False Negative                               1            1            1   \n",
      "TPR: (Sensitivity, hit rate, recall)             0            0            0   \n",
      "TNR=SPC: (Specificity)                           1            1            1   \n",
      "PPV: Pos Pred Value (Precision)                NaN          NaN          NaN   \n",
      "NPV: Neg Pred Value                       0.999956     0.999956     0.999956   \n",
      "FPR: False-out                                   0            0            0   \n",
      "FDR: False Discovery Rate                      NaN          NaN          NaN   \n",
      "FNR: Miss Rate                                   1            1            1   \n",
      "ACC: Accuracy                             0.999956     0.999956     0.999956   \n",
      "F1 score                                         0            0            0   \n",
      "MCC: Matthews correlation coefficient          NaN          NaN          NaN   \n",
      "Informedness                                     0            0            0   \n",
      "Markedness                                     NaN          NaN          NaN   \n",
      "Prevalence                             4.43597e-05  4.43597e-05  4.43597e-05   \n",
      "LR+: Positive likelihood ratio                 NaN          NaN          NaN   \n",
      "LR-: Negative likelihood ratio                   1            1            1   \n",
      "DOR: Diagnostic odds ratio                     NaN          NaN          NaN   \n",
      "FOR: False omission rate               4.43597e-05  4.43597e-05  4.43597e-05   \n",
      "\n",
      "Classes                                      38701        42689        47114  \\\n",
      "Population                                   22543        22543        22543   \n",
      "P: Condition positive                            1            1            1   \n",
      "N: Condition negative                        22542        22542        22542   \n",
      "Test outcome positive                            0            0            0   \n",
      "Test outcome negative                        22543        22543        22543   \n",
      "TP: True Positive                                0            0            0   \n",
      "TN: True Negative                            22542        22542        22542   \n",
      "FP: False Positive                               0            0            0   \n",
      "FN: False Negative                               1            1            1   \n",
      "TPR: (Sensitivity, hit rate, recall)             0            0            0   \n",
      "TNR=SPC: (Specificity)                           1            1            1   \n",
      "PPV: Pos Pred Value (Precision)                NaN          NaN          NaN   \n",
      "NPV: Neg Pred Value                       0.999956     0.999956     0.999956   \n",
      "FPR: False-out                                   0            0            0   \n",
      "FDR: False Discovery Rate                      NaN          NaN          NaN   \n",
      "FNR: Miss Rate                                   1            1            1   \n",
      "ACC: Accuracy                             0.999956     0.999956     0.999956   \n",
      "F1 score                                         0            0            0   \n",
      "MCC: Matthews correlation coefficient          NaN          NaN          NaN   \n",
      "Informedness                                     0            0            0   \n",
      "Markedness                                     NaN          NaN          NaN   \n",
      "Prevalence                             4.43597e-05  4.43597e-05  4.43597e-05   \n",
      "LR+: Positive likelihood ratio                 NaN          NaN          NaN   \n",
      "LR-: Negative likelihood ratio                   1            1            1   \n",
      "DOR: Diagnostic odds ratio                     NaN          NaN          NaN   \n",
      "FOR: False omission rate               4.43597e-05  4.43597e-05  4.43597e-05   \n",
      "\n",
      "Classes                                      53771        54451        57715  \n",
      "Population                                   22543        22543        22543  \n",
      "P: Condition positive                            1            1            1  \n",
      "N: Condition negative                        22542        22542        22542  \n",
      "Test outcome positive                            0            0            0  \n",
      "Test outcome negative                        22543        22543        22543  \n",
      "TP: True Positive                                0            0            0  \n",
      "TN: True Negative                            22542        22542        22542  \n",
      "FP: False Positive                               0            0            0  \n",
      "FN: False Negative                               1            1            1  \n",
      "TPR: (Sensitivity, hit rate, recall)             0            0            0  \n",
      "TNR=SPC: (Specificity)                           1            1            1  \n",
      "PPV: Pos Pred Value (Precision)                NaN          NaN          NaN  \n",
      "NPV: Neg Pred Value                       0.999956     0.999956     0.999956  \n",
      "FPR: False-out                                   0            0            0  \n",
      "FDR: False Discovery Rate                      NaN          NaN          NaN  \n",
      "FNR: Miss Rate                                   1            1            1  \n",
      "ACC: Accuracy                             0.999956     0.999956     0.999956  \n",
      "F1 score                                         0            0            0  \n",
      "MCC: Matthews correlation coefficient          NaN          NaN          NaN  \n",
      "Informedness                                     0            0            0  \n",
      "Markedness                                     NaN          NaN          NaN  \n",
      "Prevalence                             4.43597e-05  4.43597e-05  4.43597e-05  \n",
      "LR+: Positive likelihood ratio                 NaN          NaN          NaN  \n",
      "LR-: Negative likelihood ratio                   1            1            1  \n",
      "DOR: Diagnostic odds ratio                     NaN          NaN          NaN  \n",
      "FOR: False omission rate               4.43597e-05  4.43597e-05  4.43597e-05  \n",
      "\n",
      "[26 rows x 624 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicted      0  1  2  3  4  5  6  7  8  9   ...     16500  20741  22174  \\\n",
       "Actual                                        ...                           \n",
       "0          19017  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "1            587  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "2            103  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "3            120  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "4            539  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "5            146  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "6             35  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "7             15  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8             15  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "9             12  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "10            15  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "11             9  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "12             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "13             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "14             4  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "15             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "16             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "18             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "19             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "20            12  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "21             6  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "22             6  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "23            10  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "24             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "25             1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "26             8  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "27             4  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "28             7  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "29             3  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "30             5  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "...          ... .. .. .. .. .. .. .. .. ..   ...       ...    ...    ...   \n",
       "8209           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8212           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8213           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8216           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8217           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8220           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8221           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8224           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8228           2  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8229           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8232           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8233           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8579           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "8890           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "9645           1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "10499          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "11675          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "12112          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "12931          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "13067          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "16500          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "20741          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "22174          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "38701          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "42689          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "47114          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "53771          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "54451          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "57715          1  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "__all__    22543  0  0  0  0  0  0  0  0  0   ...         0      0      0   \n",
       "\n",
       "Predicted  38701  42689  47114  53771  54451  57715  __all__  \n",
       "Actual                                                        \n",
       "0              0      0      0      0      0      0    19017  \n",
       "1              0      0      0      0      0      0      587  \n",
       "2              0      0      0      0      0      0      103  \n",
       "3              0      0      0      0      0      0      120  \n",
       "4              0      0      0      0      0      0      539  \n",
       "5              0      0      0      0      0      0      146  \n",
       "6              0      0      0      0      0      0       35  \n",
       "7              0      0      0      0      0      0       15  \n",
       "8              0      0      0      0      0      0       15  \n",
       "9              0      0      0      0      0      0       12  \n",
       "10             0      0      0      0      0      0       15  \n",
       "11             0      0      0      0      0      0        9  \n",
       "12             0      0      0      0      0      0        3  \n",
       "13             0      0      0      0      0      0        3  \n",
       "14             0      0      0      0      0      0        4  \n",
       "15             0      0      0      0      0      0        3  \n",
       "16             0      0      0      0      0      0        1  \n",
       "18             0      0      0      0      0      0        3  \n",
       "19             0      0      0      0      0      0        1  \n",
       "20             0      0      0      0      0      0       12  \n",
       "21             0      0      0      0      0      0        6  \n",
       "22             0      0      0      0      0      0        6  \n",
       "23             0      0      0      0      0      0       10  \n",
       "24             0      0      0      0      0      0        1  \n",
       "25             0      0      0      0      0      0        1  \n",
       "26             0      0      0      0      0      0        8  \n",
       "27             0      0      0      0      0      0        4  \n",
       "28             0      0      0      0      0      0        7  \n",
       "29             0      0      0      0      0      0        3  \n",
       "30             0      0      0      0      0      0        5  \n",
       "...          ...    ...    ...    ...    ...    ...      ...  \n",
       "8209           0      0      0      0      0      0        1  \n",
       "8212           0      0      0      0      0      0        2  \n",
       "8213           0      0      0      0      0      0        1  \n",
       "8216           0      0      0      0      0      0        1  \n",
       "8217           0      0      0      0      0      0        1  \n",
       "8220           0      0      0      0      0      0        2  \n",
       "8221           0      0      0      0      0      0        1  \n",
       "8224           0      0      0      0      0      0        2  \n",
       "8228           0      0      0      0      0      0        2  \n",
       "8229           0      0      0      0      0      0        1  \n",
       "8232           0      0      0      0      0      0        1  \n",
       "8233           0      0      0      0      0      0        1  \n",
       "8579           0      0      0      0      0      0        1  \n",
       "8890           0      0      0      0      0      0        1  \n",
       "9645           0      0      0      0      0      0        1  \n",
       "10499          0      0      0      0      0      0        1  \n",
       "11675          0      0      0      0      0      0        1  \n",
       "12112          0      0      0      0      0      0        1  \n",
       "12931          0      0      0      0      0      0        1  \n",
       "13067          0      0      0      0      0      0        1  \n",
       "16500          0      0      0      0      0      0        1  \n",
       "20741          0      0      0      0      0      0        1  \n",
       "22174          0      0      0      0      0      0        1  \n",
       "38701          0      0      0      0      0      0        1  \n",
       "42689          0      0      0      0      0      0        1  \n",
       "47114          0      0      0      0      0      0        1  \n",
       "53771          0      0      0      0      0      0        1  \n",
       "54451          0      0      0      0      0      0        1  \n",
       "57715          0      0      0      0      0      0        1  \n",
       "__all__        0      0      0      0      0      0    22543  \n",
       "\n",
       "[625 rows x 625 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Multinomial Naive Bayes model PredictedResults Shape: '(22543,)'</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4> Multinomial Naive Bayes model ExpectedResults Shape: '(22543,)'</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Accuracy</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.844"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>precision</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.712"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>recall</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.844"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>f-score</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.772"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~End Of Multinomial Naive Bayes model~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print(\"~~~~~~~~~~~~~~~~~~~Start Of Multinomial Naive Bayes model~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "# fit a Multinomial Naive Bayes model to the data\n",
    "MNBmodel = MultinomialNB()\n",
    "MNBmodel.fit(Traindata, Trainlabel)\n",
    "print(MNBmodel)\n",
    "# make predictions\n",
    "MNBexpected = Testlabel\n",
    "MNBpredicted = MNBmodel.predict(Testdata)\n",
    "\n",
    "MNBcm = ConfusionMatrix(MNBexpected, MNBpredicted)\n",
    "#display(MNBexpected.shape)\n",
    "#display(MNBpredicted.shape)\n",
    "MNBexpected = np.array(MNBexpected)\n",
    "MNBpredicted = np.array(MNBpredicted)\n",
    "MNBcm.print_stats()\n",
    "\n",
    "np.savetxt('MNBexpected.txt', MNBexpected, fmt='%01d')\n",
    "np.savetxt('MNBpredicted.txt', MNBpredicted, fmt='%01d')\n",
    "\n",
    "display(MNBcm)\n",
    "display(HTML(\"<h4> Multinomial Naive Bayes model PredictedResults Shape: '{MNBP}'</h4>\".\n",
    "                     format(ColumnName=ColumnName, MNBP=MNBexpected.shape))) #GNBexpected.shape)\n",
    "display(HTML(\"<h4> Multinomial Naive Bayes model ExpectedResults Shape: '{MNBE}'</h4>\".\n",
    "                     format(ColumnName=ColumnName, MNBE=MNBpredicted.shape)))\n",
    "#display(GNBpredicted.shape)\n",
    "MNBcm.stats()\n",
    "\n",
    "MNBaccuracy = accuracy_score(MNBexpected, MNBpredicted)\n",
    "MNBprecision = precision_score(MNBexpected, MNBpredicted, average='weighted')\n",
    "MNBrecall = recall_score(MNBexpected, MNBpredicted, average='weighted')\n",
    "MNBf1 = 2 * (MNBprecision * MNBrecall) / (MNBprecision + MNBrecall)\n",
    "\n",
    "display(HTML(\"<h3>Accuracy</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', MNBaccuracy)))\n",
    "\n",
    "display(HTML(\"<h3>precision</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', MNBprecision))) \n",
    "\n",
    "display(HTML(\"<h3>recall</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', MNBrecall)))\n",
    "\n",
    "display(HTML(\"<h3>f-score</h3>\"))\n",
    "display(HTML(str.format('{0:.3f}', MNBf1)))\n",
    "\n",
    "print(\"~~~~~~~~~~~~~~~~~~~End Of Multinomial Naive Bayes model~~~~~~~~~~~~~~~~~~~\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~End Of Image Preperation~~~\n"
     ]
    }
   ],
   "source": [
    "# ImageCreation Function\n",
    "def CreateGrayScaleImage(DataFrameX):\n",
    "    ImageList = []\n",
    "    IDX = 0\n",
    "    # Arguments DataFrameX sent as DataFrame\n",
    "    for index, row in DataFrameX.iterrows():\n",
    "        #print(IDX)\n",
    "        # Get all the column data from the DataFrame row\n",
    "        IMGDT = DataFrameX.iloc[IDX,1:124]\n",
    "        #print(IMGDT)\n",
    "        #RowType = IMGDT['labels']\n",
    "        # Convert the data to Numpy Array\n",
    "        IDT = np.array(IMGDT)\n",
    "        # Convert the data to Binary\n",
    "        ISA = np.select([IDT <= .5, IDT>.5], [np.zeros_like(IDT), np.ones_like(IDT)])\n",
    "        # Create the Numpy array of converted data\n",
    "        img = np.array(ISA * 255, dtype = np.uint8)\n",
    "        # Create a grayscale image using CV2 function\n",
    "        grayscale = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 0)\n",
    "        # Recsale created Grascale Image to 32x32\n",
    "        Image32_32 = cv2.resize(grayscale, (32,32))\n",
    "        # Add new axies/dimension to the image\n",
    "        Image32_32_1 = Image32_32[:, :, np.newaxis]\n",
    "        ImageList.append(Image32_32_1)\n",
    "        # Clear up the Numply Array for next operation and increment the Index\n",
    "        np.delete(img, 1, 0)\n",
    "        IDX = IDX+1\n",
    "        \n",
    "    return ImageList\n",
    "\n",
    "#  empty regular list\n",
    "ValImageArray = [] \n",
    "ValLable1 = []\n",
    "TrainImageArray = []\n",
    "TrainLable1 = []\n",
    "\n",
    "# Set The Index Column in DataFrame\n",
    "NewTrainingData.set_index('labels')\n",
    "\n",
    "NewTrainingData1 = NewTrainingData.sample(n=50, random_state=2) #head(150)\n",
    "TrainLable1 = np.array(NewTrainingData1['labels'])\n",
    "TrainImageArray = CreateGrayScaleImage(NewTrainingData1)\n",
    "\n",
    "#print(TrainImageArray)\n",
    "#print(TrainLable1)\n",
    "#print(len(TrainLable1))\n",
    "#print(len(TrainImageArray))\n",
    "\n",
    "TrainLableT1=TrainLable1[0:35]\n",
    "TrainLableV1=TrainLable1[35:50]\n",
    "TrainImageArrayT1=TrainImageArray[0:35]\n",
    "TrainImageArrayV1=TrainImageArray[35:50]\n",
    "\n",
    "#print(len(TrainLableT1))\n",
    "#print(len(TrainImageArrayT1))\n",
    "#print(len(TrainLableV1))\n",
    "#print(len(TrainImageArrayV1))\n",
    "\n",
    "NewTestData1 = NewTestData.sample(n=50, random_state=2)\n",
    "TestLable1 = np.array(NewTestData1['labels'])\n",
    "TestImageArray = CreateGrayScaleImage(NewTestData1)\n",
    "\n",
    "print(\"~~~End Of Image Preperation~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apatkar/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 124 #Size/Numbers of our Attribute/Columns\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Hyperparameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "\n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "\n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)\n",
    "\n",
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "124 0 124\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.733\n",
      "\n",
      "124 0 124\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.533\n",
      "\n",
      "124 0 124\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.533\n",
      "\n",
      "124 0 124\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.533\n",
      "\n",
      "124 0 124\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.733\n",
      "\n",
      "124 0 124\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "124 0 124\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "124 0 124\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.867\n",
      "\n",
      "124 0 124\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "124 0 124\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "Model saved\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(TrainImageArray) #X_train)\n",
    "    \n",
    "    assert(len(TrainImageArray) == len(TrainLable1))\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        x_train, y_train = shuffle(TrainImageArrayT1, TrainLableT1) #X_train, Y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            print(end,offset,BATCH_SIZE)\n",
    "            batch_x, batch_y = x_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(TrainImageArrayV1, TrainLableV1) #X_validation, Y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(TestImageArray, TestLable1) #X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "def Create28x28GrayScaleImage(Row):\n",
    "    #display(Row)\n",
    "    IMGDT = Row.iloc[1:124]\n",
    "    # Convert the data to Numpy Array\n",
    "    IDT = np.array(IMGDT)\n",
    "    # Convert the data to Binary\n",
    "    ISA = np.select([IDT <= .5, IDT>.5], [np.zeros_like(IDT), np.ones_like(IDT)])\n",
    "    # Create the Numpy array of converted data\n",
    "    img = np.array(ISA * 255, dtype = np.uint8)\n",
    "    # Create a grayscale image using CV2 function\n",
    "    grayscale = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 0)\n",
    "    # Recsale created Grascale Image to 28x28\n",
    "    Image28x28 = cv2.resize(grayscale, (28,28))\n",
    "    # Add new axies/dimension to the image\n",
    "    #Image32_32_1 = Image32_32[:, :, np.newaxis]\n",
    "        \n",
    "    return Image28x28\n",
    "\n",
    "NewTrainingData2 = NewTrainingData.sample(n=10000, random_state=2)\n",
    "TrainLable2 = np.array(NewTrainingData2['labels'])\n",
    "\n",
    "TRIMGLst = []\n",
    "for index, Trainrow in NewTrainingData2.iterrows():\n",
    "    TRIMGLst.append(Create28x28GrayScaleImage(Trainrow))\n",
    "\n",
    "NewTrainingData3 = np.array(TRIMGLst)\n",
    "\n",
    "NewTestData2 = NewTestData.sample(n=10000, random_state=2)\n",
    "TestLable2 = np.array(NewTestData2['labels'])\n",
    "\n",
    "TSIMGLst = []\n",
    "for index, Testrow in NewTestData2.iterrows():\n",
    "    TSIMGLst.append(Create28x28GrayScaleImage(Testrow))\n",
    "\n",
    "NewTestData3 = np.array(TSIMGLst)\n",
    "\n",
    "# Convert images into 28x28 (they are 32x32)\n",
    "train_xdata = NewTrainingData3\n",
    "test_xdata = NewTestData3\n",
    " \n",
    "# Above Converted labels into one-hot encoded vectors\n",
    "train_labels = TrainLable2\n",
    "test_labels = TestLable2\n",
    "\n",
    "display(train_labels)\n",
    "display(test_labels)\n",
    "print(\"~~~End Of Image Preperation2 Creation~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~End Of My TF Model Creation~~~\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters\n",
    "batch_size = 1000\n",
    "learning_rate = 0.0001\n",
    "evaluation_size = 500\n",
    "image_width = train_xdata[0].shape[0]\n",
    "image_height = train_xdata[0].shape[1]\n",
    "target_size = max(train_labels) + 1\n",
    "num_channels = 1 # greyscale = 1 channel\n",
    "generations = 500\n",
    "eval_every = 5\n",
    "conv1_features = 25\n",
    "conv2_features = 50\n",
    "max_pool_size1 = 2 # NxN window for 1st max pool layer\n",
    "max_pool_size2 = 2 # NxN window for 2nd max pool layer\n",
    "fully_connected_size1 = 100\n",
    "\n",
    "x_input_shape = (batch_size, image_width, image_height, num_channels)\n",
    "x_input = tf.placeholder(tf.float32, shape=x_input_shape)\n",
    "y_target = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "\n",
    "eval_input_shape = (evaluation_size, image_width, image_height, num_channels)\n",
    "eval_input = tf.placeholder(tf.float32, shape=eval_input_shape)\n",
    "eval_target = tf.placeholder(tf.int32, shape=(evaluation_size))\n",
    "\n",
    "# Convolutional layer variables\n",
    "conv1_weight = tf.Variable(tf.truncated_normal([4, 4, num_channels, conv1_features],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "conv1_bias = tf.Variable(tf.zeros([conv1_features], dtype=tf.float32))\n",
    "\n",
    "conv2_weight = tf.Variable(tf.truncated_normal([4, 4, conv1_features, conv2_features],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "conv2_bias = tf.Variable(tf.zeros([conv2_features], dtype=tf.float32))\n",
    "\n",
    "#display(conv1_weight)\n",
    "#display(conv1_bias)\n",
    "#display(conv2_weight)\n",
    "#display(conv2_bias)\n",
    "# fully connected variables\n",
    "resulting_width = image_width // (max_pool_size1 * max_pool_size2)\n",
    "resulting_height = image_height // (max_pool_size1 * max_pool_size2)\n",
    "full1_input_size = resulting_width * resulting_height * conv2_features\n",
    "full1_weight = tf.Variable(tf.truncated_normal([full1_input_size, fully_connected_size1],\n",
    "                          stddev=0.1, dtype=tf.float32))\n",
    "full1_bias = tf.Variable(tf.truncated_normal([fully_connected_size1], stddev=0.1, dtype=tf.float32))\n",
    "full2_weight = tf.Variable(tf.truncated_normal([fully_connected_size1, target_size],\n",
    "                                               stddev=0.1, dtype=tf.float32))\n",
    "full2_bias = tf.Variable(tf.truncated_normal([target_size], stddev=0.1, dtype=tf.float32))\n",
    "print(\"~~~End Of My TF Model Creation~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 5. Train Loss: 35.02. Train Acc (Test Acc): 80.60 (57.20)\n",
      "Generation # 10. Train Loss: 9.37. Train Acc (Test Acc): 89.10 (68.60)\n",
      "Generation # 15. Train Loss: 6.22. Train Acc (Test Acc): 90.20 (85.20)\n",
      "Generation # 20. Train Loss: 3.56. Train Acc (Test Acc): 89.60 (71.60)\n",
      "Generation # 25. Train Loss: 0.55. Train Acc (Test Acc): 97.60 (81.60)\n",
      "Generation # 30. Train Loss: 0.57. Train Acc (Test Acc): 98.60 (79.80)\n",
      "Generation # 35. Train Loss: 0.44. Train Acc (Test Acc): 98.90 (76.40)\n",
      "Generation # 40. Train Loss: 0.16. Train Acc (Test Acc): 99.20 (79.00)\n",
      "Generation # 45. Train Loss: 0.27. Train Acc (Test Acc): 99.00 (83.80)\n",
      "Generation # 50. Train Loss: 0.11. Train Acc (Test Acc): 99.20 (82.00)\n",
      "Generation # 55. Train Loss: 0.17. Train Acc (Test Acc): 99.60 (81.80)\n",
      "Generation # 60. Train Loss: 0.45. Train Acc (Test Acc): 99.30 (82.40)\n",
      "Generation # 65. Train Loss: 0.24. Train Acc (Test Acc): 99.60 (84.00)\n",
      "Generation # 70. Train Loss: 0.04. Train Acc (Test Acc): 99.60 (83.60)\n",
      "Generation # 75. Train Loss: 0.14. Train Acc (Test Acc): 99.70 (83.80)\n",
      "Generation # 80. Train Loss: 0.11. Train Acc (Test Acc): 99.60 (82.80)\n",
      "Generation # 85. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (82.00)\n",
      "Generation # 90. Train Loss: 0.24. Train Acc (Test Acc): 99.10 (81.80)\n",
      "Generation # 95. Train Loss: 0.03. Train Acc (Test Acc): 99.80 (83.20)\n",
      "Generation # 100. Train Loss: 0.09. Train Acc (Test Acc): 99.60 (84.20)\n",
      "Generation # 105. Train Loss: 0.06. Train Acc (Test Acc): 99.50 (81.60)\n",
      "Generation # 110. Train Loss: 0.06. Train Acc (Test Acc): 99.50 (81.40)\n",
      "Generation # 115. Train Loss: 0.06. Train Acc (Test Acc): 99.50 (81.20)\n",
      "Generation # 120. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (85.60)\n",
      "Generation # 125. Train Loss: 0.09. Train Acc (Test Acc): 99.40 (82.80)\n",
      "Generation # 130. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (81.40)\n",
      "Generation # 135. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (84.40)\n",
      "Generation # 140. Train Loss: 0.04. Train Acc (Test Acc): 99.50 (82.80)\n",
      "Generation # 145. Train Loss: 0.10. Train Acc (Test Acc): 99.60 (83.60)\n",
      "Generation # 150. Train Loss: 0.03. Train Acc (Test Acc): 99.80 (83.20)\n",
      "Generation # 155. Train Loss: 0.11. Train Acc (Test Acc): 99.60 (83.60)\n",
      "Generation # 160. Train Loss: 0.16. Train Acc (Test Acc): 99.50 (84.40)\n",
      "Generation # 165. Train Loss: 0.16. Train Acc (Test Acc): 99.40 (80.00)\n",
      "Generation # 170. Train Loss: 0.03. Train Acc (Test Acc): 99.80 (83.00)\n",
      "Generation # 175. Train Loss: 0.17. Train Acc (Test Acc): 99.40 (83.00)\n",
      "Generation # 180. Train Loss: 0.07. Train Acc (Test Acc): 99.50 (81.40)\n",
      "Generation # 185. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (80.20)\n",
      "Generation # 190. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (84.80)\n",
      "Generation # 195. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (84.00)\n",
      "Generation # 200. Train Loss: 0.06. Train Acc (Test Acc): 99.50 (81.60)\n",
      "Generation # 205. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (84.00)\n",
      "Generation # 210. Train Loss: 0.11. Train Acc (Test Acc): 99.50 (80.20)\n",
      "Generation # 215. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (84.00)\n",
      "Generation # 220. Train Loss: 0.04. Train Acc (Test Acc): 99.60 (88.40)\n",
      "Generation # 225. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (89.20)\n",
      "Generation # 230. Train Loss: 0.06. Train Acc (Test Acc): 99.80 (86.20)\n",
      "Generation # 235. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (86.20)\n",
      "Generation # 240. Train Loss: 0.06. Train Acc (Test Acc): 99.80 (88.20)\n",
      "Generation # 245. Train Loss: 0.02. Train Acc (Test Acc): 99.70 (84.00)\n",
      "Generation # 250. Train Loss: 0.01. Train Acc (Test Acc): 99.90 (84.60)\n",
      "Generation # 255. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (85.80)\n",
      "Generation # 260. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (85.00)\n",
      "Generation # 265. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (85.00)\n",
      "Generation # 270. Train Loss: 0.01. Train Acc (Test Acc): 99.50 (87.40)\n",
      "Generation # 275. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (85.00)\n",
      "Generation # 280. Train Loss: 0.07. Train Acc (Test Acc): 99.70 (86.20)\n",
      "Generation # 285. Train Loss: 0.06. Train Acc (Test Acc): 99.70 (85.20)\n",
      "Generation # 290. Train Loss: 0.06. Train Acc (Test Acc): 99.80 (88.60)\n",
      "Generation # 295. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (86.40)\n",
      "Generation # 300. Train Loss: 0.02. Train Acc (Test Acc): 99.80 (86.00)\n",
      "Generation # 305. Train Loss: 0.05. Train Acc (Test Acc): 99.60 (85.40)\n",
      "Generation # 310. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (84.80)\n",
      "Generation # 315. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (85.40)\n",
      "Generation # 320. Train Loss: 0.05. Train Acc (Test Acc): 99.80 (84.20)\n",
      "Generation # 325. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (86.60)\n",
      "Generation # 330. Train Loss: 0.02. Train Acc (Test Acc): 99.80 (87.20)\n",
      "Generation # 335. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (87.20)\n",
      "Generation # 340. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (86.60)\n",
      "Generation # 345. Train Loss: 0.02. Train Acc (Test Acc): 99.70 (86.20)\n",
      "Generation # 350. Train Loss: 0.02. Train Acc (Test Acc): 99.90 (89.80)\n",
      "Generation # 355. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (86.20)\n",
      "Generation # 360. Train Loss: 0.06. Train Acc (Test Acc): 99.80 (87.20)\n",
      "Generation # 365. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (87.20)\n",
      "Generation # 370. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (85.40)\n",
      "Generation # 375. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (84.00)\n",
      "Generation # 380. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (85.40)\n",
      "Generation # 385. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (85.80)\n",
      "Generation # 390. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (85.00)\n",
      "Generation # 395. Train Loss: 0.04. Train Acc (Test Acc): 99.90 (87.60)\n",
      "Generation # 400. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (87.40)\n",
      "Generation # 405. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (86.00)\n",
      "Generation # 410. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (88.00)\n",
      "Generation # 415. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (88.20)\n",
      "Generation # 420. Train Loss: 0.02. Train Acc (Test Acc): 99.50 (85.60)\n",
      "Generation # 425. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (86.60)\n",
      "Generation # 430. Train Loss: 0.02. Train Acc (Test Acc): 99.80 (86.80)\n",
      "Generation # 435. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (81.40)\n",
      "Generation # 440. Train Loss: 0.02. Train Acc (Test Acc): 99.80 (87.60)\n",
      "Generation # 445. Train Loss: 0.02. Train Acc (Test Acc): 99.60 (89.80)\n",
      "Generation # 450. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (88.20)\n",
      "Generation # 455. Train Loss: 0.02. Train Acc (Test Acc): 99.80 (84.40)\n",
      "Generation # 460. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (84.80)\n",
      "Generation # 465. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (84.60)\n",
      "Generation # 470. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (84.00)\n",
      "Generation # 475. Train Loss: 0.01. Train Acc (Test Acc): 99.90 (85.00)\n",
      "Generation # 480. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (86.60)\n",
      "Generation # 485. Train Loss: 0.03. Train Acc (Test Acc): 99.80 (87.00)\n",
      "Generation # 490. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (85.40)\n",
      "Generation # 495. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (84.40)\n",
      "Generation # 500. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (86.00)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Model Operations\n",
    "def my_conv_net(input_data):\n",
    "    # First Conv-ReLU-MaxPool Layer\n",
    "    conv1 = tf.nn.conv2d(input_data, conv1_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "    max_pool1 = tf.nn.max_pool(relu1, ksize=[1, max_pool_size1, max_pool_size1, 1],\n",
    "                               strides=[1, max_pool_size1, max_pool_size1, 1], padding='SAME')\n",
    "    tf.nn.dropout(0.2,0.1)\n",
    "    # Second Conv-ReLU-MaxPool Layer\n",
    "    conv2 = tf.nn.conv2d(max_pool1, conv2_weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
    "    max_pool2 = tf.nn.max_pool(relu2, ksize=[1, max_pool_size2, max_pool_size2, 1],\n",
    "                               strides=[1, max_pool_size2, max_pool_size2, 1], padding='SAME')\n",
    "    tf.nn.dropout(0.01,0.01)\n",
    "    # Transform Output into a 1xN layer for next fully connected layer\n",
    "    final_conv_shape = max_pool2.get_shape().as_list()\n",
    "    final_shape = final_conv_shape[1] * final_conv_shape[2] * final_conv_shape[3]\n",
    "    flat_output = tf.reshape(max_pool2, [final_conv_shape[0], final_shape])\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    fully_connected1 = tf.nn.relu(tf.add(tf.matmul(flat_output, full1_weight), full1_bias))\n",
    "\n",
    "    # Second Fully Connected Layer\n",
    "    final_model_output = tf.add(tf.matmul(fully_connected1, full2_weight), full2_bias)\n",
    "    \n",
    "    return(final_model_output)\n",
    "\n",
    "model_output = my_conv_net(x_input)\n",
    "test_model_output = my_conv_net(eval_input)\n",
    "\n",
    "# Declare Loss Function (softmax cross entropy)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model_output, labels=y_target))\n",
    "\n",
    "# Create a prediction function\n",
    "prediction = tf.nn.softmax(model_output)\n",
    "test_prediction = tf.nn.softmax(test_model_output)\n",
    "\n",
    "# Create accuracy function\n",
    "def get_accuracy(logits, targets):\n",
    "    batch_predictions = np.argmax(logits, axis=1)\n",
    "    num_correct = np.sum(np.equal(batch_predictions, targets))\n",
    "    return(100. * num_correct/batch_predictions.shape[0])\n",
    "\n",
    "# Create an optimizer\n",
    "my_optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "train_step = my_optimizer.minimize(loss)\n",
    "\n",
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Start training loop\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for i in range(generations):\n",
    "    rand_index = np.random.choice(len(train_xdata), size=batch_size)\n",
    "    rand_x = train_xdata[rand_index]\n",
    "    rand_x = np.expand_dims(rand_x, 3)\n",
    "    rand_y = train_labels[rand_index]\n",
    "    train_dict = {x_input: rand_x, y_target: rand_y}\n",
    "    \n",
    "    sess.run(train_step, feed_dict=train_dict)\n",
    "    temp_train_loss, temp_train_preds = sess.run([loss, prediction], feed_dict=train_dict)\n",
    "    temp_train_acc = get_accuracy(temp_train_preds, rand_y)\n",
    "    \n",
    "    if (i+1) % eval_every == 0:\n",
    "        eval_index = np.random.choice(len(test_xdata), size=evaluation_size)\n",
    "        #display(len(test_xdata),eval_index,len(test_labels))\n",
    "        eval_x = test_xdata[eval_index]\n",
    "        eval_x = np.expand_dims(eval_x, 3)\n",
    "        eval_y = test_labels[eval_index]\n",
    "        test_dict = {eval_input: eval_x, eval_target: eval_y}\n",
    "        test_preds = sess.run(test_prediction, feed_dict=test_dict)\n",
    "        temp_test_acc = get_accuracy(test_preds, eval_y)\n",
    "        \n",
    "        # Record and print results\n",
    "        train_loss.append(temp_train_loss)\n",
    "        train_acc.append(temp_train_acc)\n",
    "        test_acc.append(temp_test_acc)\n",
    "        acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
    "        acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "        print('Generation # {}. Train Loss: {:.2f}. Train Acc (Test Acc): {:.2f} ({:.2f})'.format(*acc_and_loss))\n",
    "        \n",
    "display(np.mean(temp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6cd050908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzsnXd4VFX6xz8nCSVAEAhIlU6C1BAC\nSLGAIkhZC7JYkCIWXNgVRVd214Kui6ir6yIWWCn6E1AsoEGQZqEJSK8m9BokCSFAIIEk7++PM5NM\nkkkyqQPM+3meee7cc+899703mfu95z3veY8RERRFURQlO37eNkBRFEW5PFGBUBRFUdyiAqEoiqK4\nRQVCURRFcYsKhKIoiuIWFQhFURTFLSoQitcxxvgbY84ZY+pfBrasMsYM87YdinI5oAKhFBjHw9z5\nSTfGXHBZf7Cg9YlImohUEpHDJWFvcWCM+cjlGi8aYy65rEcWod7RxpjvPdz3S2NMsjGmamHPpygF\nQQVCKTCOh3klEakEHAb6u5TNyr6/MSag9K0sXkTkEZdrfgOY5XLN/Uv6/A5R6AckAfeV9PmynfuK\n//sphUMFQil2jDGvGmM+N8bMMcacBQYbYzobY9YaY04bY2KMMZOMMWUc+wcYY8QY09Cx/qlj+yJj\nzFljzC/GmEa5nMvP8WZ9wlH3T8aY612251mXMaa3MSbKGJNojPkvYIpw3TcbY9Y77NhojOnssm2k\nMeaQw4Z9xph7jDEdgLeA2xwtkaN5VH8/cMix/9Bs5y1jjHnZGHPAGHPGYUMNx7Z2jnuS4LjvYxzl\nXxpjxrnU0c8Y85vLepwx5mljzC7glKPsZWPMQcc1bDfG3OGyvzHG/NlxL88aY7YZY1o4jvk4m70z\njDGvFvgGK6WPiOhHP4X+AAeB27KVvQpcBPpjX0ICgQ5AJyAAaAxEA6Md+wcAAjR0rH8KxAERQBng\nc+DTXM7vBwwDgoDywGRgg8v2XOsCrgXOAXc7tj0LpALD8rnmV4GZ2cqaAPFAD4dNfwBOAtcANbAP\n2caOfesCzR3fRwPfe3Cf1wEvAg2BdCDUZdvLwAbHffUD2jvOG+ywaSRQ1lHWwXHMl8A4lzr6Ab+5\nrMcBa4HaQKCj7D6gFuAPDAfOANUc24YD+4G2WJFt7rjOJo79Kjj2CwQSndevn8v7oy0IpaRYJSKR\nIpIuIhdE5FcRWSciqSKyH5gK3JzH8V+KyAYRuQTMAsLc7eSof6aInBWRZGA80N4YU9GDuvoBW0Rk\nnmPbW0BsIa93GDBXRH5w2PQtsAe4DftAN0BLY0w5ETkmIr/lUVcWjDHNgY7AbBE5CPwCDHHZ5RHg\nORHZ7zj3RhFJBO4BdonIhyJyUUQSReTXAlzT2yISIyIXAETkMxE5IbbPaAZWANu52PAvEdkqlt8c\n17kP2Arc6djvTiCqINeveA8VCKWkOOK6Yoxpboz5zuEKOgO8AlTP4/gTLt/PA5Xc7eSIgHrDGLPf\nUe9exybXunOrq46rnSKSDuTl5smLBsAwh3vptDHmNFaI6ohIPNYt9BTwuzHmG2NMkwLUPRRYLyLO\na5sFPORwr/lj3/L3uTnuulzKPSX73/Axh2vJeX0NybzPeZ3rY2Cw4/tg4P+KYJNSiqhAKCVF9jTB\nU4AdQFMRqYx1lxTa3+/CEKAP1rVzDdDUUe5J3THYB5s9wBg/oF4h7TgCfCgiVVw+FUXkXQAR+VZE\nemDdLsexrjDIeZ+y4LBpMNDaIa4ngH867L5FRNIc1+FOcI7kUg62s7uCy3otN/tk2GaMaQG8DYzA\nupWqYN2Lzvuc17nmAjc66ugBfJbLfsplhgqEUloEYX3PSY5O5MeLsd4UrK+9AvCvAhy7AAgzxtzp\niNR5CttfUBhmAvcbY7o73uwDjTG3GWNqGmOuM8b0McYEAsnYh3Oa47jfgfom90ihWx02hbl8WgLf\nkNlZ/RHwmjGmoePc4caYa4CvgRaON/+yxphrjDERjmO2AP0dZfWwfSF5UQnrKosF/Iwxo7AtCCcf\nAX83xrRxdFg3N8bUBRCRM8B3WGFYJiKFdeMppYwKhFJajMU+0M5iWxOfF1O9M7Bv5MeBncAaTw8U\nkd+BQcCbWIGpj+0MLjAisgcYiO3Ajse+Xf8Z+4YdAPwDKwZx2If8k45DFwLHgFhjzCE3VQ8FPheR\naIf//4SInAAmAQOMMZUc51wC/AycBt4HyjpcWz2xLZBYYDfQxVHv/7BRUUeAb4HZ+VzfemAasBl7\nr+tiRcbJTOBd4Ctsp/TnQGWX7R8DrVH30hWFEdEJgxRFKVkc7qU1QC1HMIFyBaAtCEVRShRHR/pT\nwCcqDlcWOkJSUZQSwxhzLXAAG/Lby8vmKAVEXUyKoiiKW9TFpCiKorjlinYxVa9eXRo2bOhtMxRF\nUa4oNm7cGCci+YZ0X9EC0bBhQzZs2OBtMxRFUa4ocgmpzoG6mBRFURS3qEAoiqIoblGBUBRFUdyi\nAqEoiqK4RQVCURRFcUuJCYQxZrox5qQxZodLWTVjzFJjzB7Hsqqj3Bg7LeRex1SF4SVll6IoiuIZ\nJdmCmAn0zlY2DlguIs2A5Y51gDuAZo7PY8AHJWiXoiiK4gElNg5CRFYYxyT0LtwJ3OL4/jHwE/Cc\no/wTsXk/1hpjqhhjaotITEnZpxQMEeH48eNERUURHR1NYGAggwcPxt/fv9TtEBH8/C5P72h6ejpA\nFvvi4uJYtGgR5cuXZ8CAAXnaLiIYUxzzKFlSU1OZNWsWSUlJhISEEBISQr169Qp8/5KSkli6dCnH\njx9n0KBBBAcHF9juS5cuUaZMGbflFy9ezFivUKFCnnWJCEePHs34X0xLS6N37940a9asQNfkTUSE\n2NjYjGs4deoUPXr0IDw83KO/f2JiIgEBAVSsWDHffYtCaQ+Uq+l86ItIjCORF9jc8q7TGx51lOUQ\nCGPMY9hWBvXr1y9Zay8DLl68SEJCAtdee22Wf5y0tDSSkpKoXLlylv2Tk5N5/fXXadKkCXfccUeO\nH3J+JCcnY4yhXLlyGWUnTpzgoYceYtmyZVn2/fTTT/n000+pWbNmlvLExEQWL17M5s2b6dy5M7fd\ndhsVKlQgLxITE5k+fTphYWF0797d7T4LFy5kzJgxHD58mGbNmmU88EJDQwkJCaFVq1ZZ7kdaWhqR\nkZHs2rWLBx98kAYNGgD2x7lixQqWLl1K586d6dGjB4GBgVnOlZKSwk8//cTy5ctJSkpya0+tWrUI\nDQ2ladOmREVFERkZyaJFi0hOTqZZs2aEhoYSExPDL7/8kiEcN9xwA++99x7h4Vm9qAcPHmTMmDEs\nXryYm266if79+3Prrbdm3LeUlBT27t1LdHQ0Bw4cIDU1NYc9fn5+tG/fnr59+1KjRg1WrlzJqFGj\n2L59e5b9AgMDM+yrXr16vg+kgwcPsnz5clJSUgB49tlnGT58OHfffTcrV64kMjKSHTt2MGjQIMaO\nHUvbtm25cOECy5cvZ8mSJezatYvo6GiOHDlCtWrVCAkJoWnTpsTHx2dcj/P+ANSrV49+/frRv39/\nWrRogTEGEWH79u1ERkayYMECYmJyvjuGhobSq1cvrr/+ekJDQ2nQoEHGC0xgYCDXXnttjmMOHz7M\n7t27iY6OZt++fVy6dCnHPsYY2rRpQ79+/ahTp06WbSLCzp07WbBgAUeOHMlxbHbOnDmTIQqJiYk5\nttepU4fbbruNSpXsrLj+/v40bNiQ0NBQateunXG/f/75Z6ZOncrw4cPzPWdRKNFkfY4WxAIRaeVY\nP+2YqtC5PUFEqhpjvgNeE5FVjvLlwF9FZGNe9UdERMiVNJL64sWLfPjhhyQkJPDoo49m/LOdO3eO\nGTNmsGrVqox9z549m+XHU7FiRZo1a0bt2rU5ePBgxj/za6+9xl//+leMMVy8eJF77rmH7777DrAP\njK5du9KhQ4eMB2l2QQH71rtx40a+/fZbfvjhBwIDA3niiScYPXo0u3fv5oEHHuDMmTO88MILdOrU\niZCQEBYvXszo0aOpUqUKb731FufPnyc6OpqNGzeyYsUKUlNTM37Y5cuXp3v37oSFhWXYERoaSrVq\n1RARZs2axTPPPMPvv/8OwKBBg3jrrbeoW7culy5dYvfu3bz44ot88803hIaG0rdvX/bs2UNUVBT7\n9+/PeFgGBARw44030r9/f8qWLcs777zD3r12Gmd/f38GDhxIjx49mDp1apYR+IGBgdx0001cc801\nGX+PFStWcO7cOcqVK0dQUJDbe3bq1KksZTVq1KBv374EBwcTFRVFVFQUQUFBGQ+7Xbt28eyzzxIX\nF8fAgQMz7sfOnTuZMGECfn5+DBw4kF9++YXo6Ohc/4+CgoKyCLiTlJQUzp49izGGFi1asHPnTurX\nr88777xDp06dMmyKjo4mOjqaqKgoTp8+net5nFSrVo077riD/v37ExwczKRJk5g1axYXL17Ez8+P\nzp07Exoayueff05SUhJhYWFERUVx4cIFKlasSMuWLQkJCaFRo0YZb8179+4lODg4Q+Sd/5dpaWms\nX7+eJUuWuBXmoKAgevfuTY8ePWjevDkhISEkJyezYMECFixYwKpVq7hw4YLb62jVqhX9+/enU6dO\nGQ9a1/tcsWLFHC8KYFs4zod5+/btadLEzqyanp7Ohg0bOHjwIADBwcH5im2FChWyvNQ4l4GBgSxe\nvJjIyEhWr16d8T998eJFzpw5k6WO66+/nv79+zNkyBBatmyZ5/lywxizUUQi8t2vlAUiCjuPbowx\npjbwk4iEGmOmOL7Pyb5fXvVfSQKxbNkyRo8eTVRUFABlypThgQceoFatWkyZMoXTp0/TqFGjjB++\n8y0vJCSEGjVqsH//fqKjo4mJicl4o4iOjmbevHk8+eSTvPnmmzz44IN88cUXvP/++7Rv3z7jjXbn\nzp0kJ+efhr9x48b069ePo0ePMm/ePMqUKcOlS5cIDQ3liy++oFWrVln23759OwMHDsy4prJly9K8\neXN69+5N//79ad++PatXryYyMpKlS5eyZ8+eLG++wcHBVK1alb1799KxY0fefvttli1bxsSJEwkI\nCKBOnToZAlCxYkVefPFFxowZQ9myZTPqSE1N5cCBA0RFRbF69WoWLFjAjh02LqJDhw48++yzdOjQ\ngffee48pU6Zw9uxZQkJCePrppxk0aBDr168nMjKSFStWZLg5AgIC6Nq1K/3793fbunBy/vx59uzZ\nw549e6hbty4dO3bM1+V2+vRpXnrpJb744ossb8EDBw7krbfe4rrr7BTZ0dHRrF27lrS0tAybGjdu\nTEhISK5v/SLC5s2biYyM5IcffuDGG2/k73//e76tt8IQExPD+vXr6dq1K9WrV8+4tqlTpzJ//nza\nt29P//79ufnmm92KWX6kpKTw888/c+zYsYyy6667jptuuinL3z876enpHDt2jKioKI4ePYrz+RYX\nF8fChQtZuXIlaWlplClThu7du9OnTx/atWtHSEgINWvWzPW+7ty5k8jISBYuXEhcXFzGtqZNm9K/\nf3+3rYviwtnSOnz4MBERERkCVRQuV4F4E4gXkYnGmHHYyc//aozpi50Ttw/QCZgkIh3zq/9yEYj0\n9HQWLlzIlClTqFy5Mv3796d3796cPXuWBQsWMG/ePJYuXUqTJk2YNGkSoaGhvPPOO0yfPp3k5GTu\nvvtuxo4dS+fOnQt83rFjx/LOO+/QsGFDDh48yL///W/Gjh2bY7+jR48SHR3N+fPn3dbVtGlTrr/+\n+owfyN69e5k8eTIBAQGMHz8+o8mbnaSkJDZs2ED9+vWpX79+ng9I14e58w328OHDDBgwgIcffjjD\nL75//37Gjx/P+fPnM96wevbs6fEP8MCBA5w+fZqwsLAsP/gzZ87w22+/ERERcVn0YThbiX5+frRr\n187b5vgEp0+fZuvWrYSHh7ttGfoKngpERqdfcX+AOdg+hEvYPoURQDA2emmPY1nNsa8B3gP2AduB\nCE/O0b59e/EmFy5ckKlTp0rz5s0FkDp16khwcLAA4u/vL4AA0qRJE3n11VflwoULWY5PSEiQ48eP\nF8mG9PR0eeONN8QYI+PHjy9SXYqi+AbABvHgGXtFTxjkrRZEXFwc77//Pu+99x4nT56kXbt2PPPM\nMwwcOBA/Pz/Wrl3LokWLMloTzZs3L9bIFHckJiZm+NAVRVHywtMWxBWd7tsb7Nmzhw4dOpCYmEjf\nvn0ZO3Yst9xySxYB6Nq1K127di1Vu1QcFEUpblQgCkB6ejoPP/wwANu2baN169ZetkhRFKXkUIEo\nAO+++y6rVq1i5syZKg6Kolz1eD+U4wph7969/O1vf6Nv374MGTLE2+YoiqKUOCoQHuB0LZUtW5Yp\nU6aUeIezoijK5YC6mDxg9+7drFy5kkmTJlG3bl1vm6MoilIqaAvCA06cOAFA27ZtvWyJoihK6aEC\n4QGxsbGAzbWjKIriK6hAeMDJkycBFQhFUXwLFQgPiI2Nxc/Pj2rVqnnbFEVRlFJDBcIDYmNjqV69\n+mWR4E1RFKW00CeeB5w8eVLdS4qi+BwqEB4QGxurAqEois+hAuEBsbGxbqcrVBRFuZpRgfAAdTEp\niuKLqEDkw6VLl0hISFCBUBTF51CByIf4+HhAx0AoiuJ7qEDkg3MUtfZBKIria6hA5IOOolYUxVdR\ngcgHzcOkKIqvogKRD+piUhTFV1GByIeTJ09qHiZFUXwSFYh8iI2NJTg4WPMwKYric+hTLx80zYai\nKL6KCkQ+nDx5UvsfFEXxSVQg8kFbEIqi+CoqEPmgAqEoiq+iApEHly5d4tSpUyoQiqL4JCoQeeDM\nw6R9EIqi+CIqEHmgo6gVRfFlVCDyQAVCURRfRgUiD5yJ+tTFpCiKL6ICkQfaglAUxZdRgciD2NhY\njDGah0lRFJ9EBSIPTp48SXBwMP7+/t42RVEUpdRRgciD2NhY7X9QFMVnUYHIAx1FrSiKL+MVgTDG\nPGmM2WGM2WmMGeMoq2aMWWqM2eNYVvWGba6cPHlSBUJRFJ+l1AXCGNMKeBToCLQF+hljmgHjgOUi\n0gxY7lgvVUSEffv2ZaxrC0JRFF/GGy2I64G1InJeRFKBn4G7gTuBjx37fAzcVdqGTZ48maZNmzJ2\n7NiMPEzaB6Eoiq/iDYHYAdxkjAk2xlQA+gDXATVFJAbAsXT7ZDbGPGaM2WCM2eAcp1AcxMTE8I9/\n/IOaNWvy9ttvc/fddwM6BkJRFBfWr4fjx71tRalR6gIhIruB14GlwPfAViC1AMdPFZEIEYkozof3\nM888w8WLF1m1ahWvvfYa3333HaACoSj5cvQoHD4MIt62pGS5cAE6dYKwMG9bUmp4pZNaRKaJSLiI\n3AScAvYAvxtjagM4lidLy54ff/yR2bNn89xzz9G0aVPGjRvHjBkzqFq1Ki1btiwtMxTlyuTttyE0\nFNLSvG1JybJpk13GxoJLX+XVjLeimK51LOsD9wBzgG+BoY5dhgLflIYtFy9eZNSoUTRq1Ihx4zL7\nxYcNG0Z8fLwKhK+RmAh/+5t9CCiesXUrJCfDCy9425KSpWtX2L7dfv/wQ+/aUkoEeOm8XxljgoFL\nwCgRSTDGTATmGmNGAIeBgaVhyLx589i9ezfffPMNgYGBWbYZY0rDBOVyITUV7rgDfvnFvhEPG+Zt\niy5/RKxAAKxY4V1bSoNWreDee2HLFm9bUip4RSBE5EY3ZfHAraVty+HDhwHo0aNHaZ9audx49lkr\nDv/+t4qDpxw7BvHxYIwVivR08LsKx99u2gRjx8L778PMmVChgrctKhWuwr9kwYiLi6NcuXJUrFjR\n26Yo3uSjj+Cdd+DJJ+2D4HLl5Eno3h327/e2JRZn62HIEEhKunzsKm6++ca2kGrUgIoVrSCePett\nq0ocFYi4OKpXr67uJF/nl1+gVy/bevjlF+tqOllqcRKe89VX8NNPMK7Ux5G6p0MHmDMHhjq6D52C\ncbXx7bfQpQtUr27Xf/wRatWCX3/1rl0ljAqEQyAUH+ejj2DePAgIsNE4338Pa9fmvn98PBw5Unr2\nORk2zNoYFVX653bHtdfCfffBDTdA794QFORtizLZsQMmTIDOnaF2bfj998LVc+SI7XPo3z+zrH17\n60r76KPisfUyRQVCBUJJTbUuA2eQQvv29iH8yy+5H9O5Mzz9dOnY50pgILz6KmzbZscfeJvZs+G3\n36xdixbB7bd72yLLmjW2dfOPf1hX0IkTsHRp4eqKjLTLP/whs6xyZRvVpC2IqxsVCIVBg+BGl7iJ\nwEBo1y53gdi+HRo1gt27S8c+JyL2gVe7thWwjRtL9/zZSUqCwYPh888zyy5cKPnznj0LBw7kvU+X\nLhAdbUc9b9tmxSI9vXDnq10bHnjARra50qoV7NplXzCuUlQgVCCUqCjIPmvgDTfYt8PsP/60NLjt\nNliyBPbsKfrD4dw5z4Vm/37rMklOhrg4uPPOop27qGzfbkWrbVu7PmUKVKoEp06V7HkfewwaN7ZL\ndzhHdF93nX24+/nZFBlDhhTufHffDbNm2VamK61bQ0oK7N1buHqvAHxaIFJTU0lISNB0Gr5MWpr9\ngWd/O7zlFvvWGReXtXzFCtt53bcvXLyY/5tsfgwaBC1awJkz+e/rHMnbvj1cc03RzpsXBw9a37rz\n89NP7vdzdkg7BaJBA/uWvm2bXU9Pt527zvXiID0dFi+2KS/ucuTzTEmxrRknH3wAERF20GP2Yy9e\nLNj5UlNzj1a68UZ47bWS/Vt4GZ8WiISEBEREWxC+zOHD9gETEpK1/J577IOxVq2s5XPn2hh4Z/9D\nUd1MCxfa5Y8/5r/vpk3WtdSqle1/uOkm+wAuTtasgfBwePTRzI9TmLKzdav1xTdsaNedOYqcwvH+\n+7aVs3ixXZ81Cz79tGj2bd0KCQkwejT06WMf3k2bwhtvZO4zd651dbk+uI8dsx3qBT3/5s32Ghcs\nyLmtcWMbTVa7duGu5QrApwUizvF2qALhwzijgbK3IJy45hdKS4Ovv7athw4d7Nt1u3ZFO/+5c3bp\nfIjmxaZNVhzKlYOaNe2b+fz5RTu/KyLw4osQHGzPdeSIbU08+aTdvnt31vuxZYttPThdL7Vq2Yfw\n1q02V9Fzz9nIppEj7fYZM2z9RUnq98MPdtm9u10GBdnWwqRJmZ3RK1bAwGyJGOrUAX//zOOzc/Qo\nvP66FR9Xjh2zy9xE4MSJ4hlVnZpqWzixsTbE+osvil5ncSAiV+ynffv2UhR+/vlnAWTZsmVFqke5\ngtm6VWTMGJG4uJzbnnlGpHnzzPWffxYBkblzi9eGfv1EGjfOf7/QUJGHH85cv/9+kRo1RFJTi8+W\nuDiR33/PWX7smEhQkMjdd4ucPGnLEhJE9u7Nul/PniJhYSI33yxSubLIkSOZ2z75xN6/FSsKb9/W\nrSJvv521bN06W+8bb4hMnmy/79iR89hBg0Tq1BFJT7friYkia9bY79u22eM+/DDrMe++a8tPnHBv\nz733ijRtWvjrERE5cECkTRuRKVPs37JRI3v/ShBgg3jwjPX6Q74on6IKxFdffSWAbNmypUj1KFcp\nr79ufyLOB2J6usjatSJJSXZ9zx6RxYsLX/8zz4i89pp9mB08mP/+6eki589nrs+ebe379NPC2+Bk\n4kSRDRvy3uc//xEJCBCpWlXk/ffdC9PcuSLt21u7pk3Luu3sWZGKFUUeeaTo9mbntttEatUS6dRJ\npEUL9/tMmWLt+u03uz5ihEivXvY60tLstnHjsh4zbpxImTJ2uzteflnEGJFz5wpv+4gRIoGBIt9+\na9ffeMPasn174evMBxUID5gyZYoAcvTo0SLVo1zBHDwokpzsftuKFfYn0rq1SJcuItlfJJ54QuSa\nazLfSAvCpUv22BEj3G/fvl1kyBCR+Pjc6zhzRqRlS/uA2rOn4DY4OXzYXuebb+a/786dIt272/07\ndRI5fdq9Xe++6/6+DB1qWxauQucpBw6ILFrk/u+1fLm1qWfP3AVzzx67zwcfiHz/fU5BaNJE5L77\nsh4zeLBIgwa52/TVV7ae9esLejWWU6esODz6aGZZbKxIuXIif/pT4er0AE8FQvsggODgYC9boniN\nbt1sR6w7OnWCBx+0/v4KFXImoWve3EbKFGaE7vr19thevez6l19mdrSKWL/9J5/AU0/Zsg8/hOHD\ns/rvg4JsX8H339uOWrCD1grKkiV26bQlL1q0gOXLbXqNiAj3SeuCgmwnsrv0NUOH2k5tR5LMAjFn\njvXPZ49OAtsnsXKl7ct58EH3xzdpAi+9ZPubHnkErr/erjtp0AAOHcp6zD33wF//mrtNrVvbpTMN\neEGZOdN2qP/pT5ll1avb6LZPPnEf3ZaUVHqz2nmiIpfrp6gtiKeeekoqVapUpDqUK5hz5+zb36uv\nFu74JUvs8T/84H57Xi2LF18U8fOzb5AiIiNHilSqJJKSkvlW2qGDyOjR1gXSr59tLeTFsmW2ztde\nK1irZuDArL75ksTTc2zcKHLLLSKPP555TM+eIq1aFd2GRx6x92nduqzlI0bY/pOCkJpqWwBjxhTO\nllatbOs0O5s2WbffmTM5t33wgXX1RUcX7pyiLiaPeOihh6Rhw4ZFquOq46GHRJ591ttWlA6bN0uR\nOp2PHLHHv/9+zm2rV9sH/N69mSLgSqdOIjfckLk+b56t68cf7UOqZUvrhnJSu7b92+RFSortuAaR\nv/zFvd88LS1reWqq7VMYPjzvuoubs2fdP/xERN56y7rNKlbMFPDkZPsg/stfinbelBSRW28Vee65\nnNuy36/0dJFdu/LvX4iMLPzD+vffC9bXkJ5uRaVduyIJuqcC4fMuphwhrs6wQ1/lxx8vjxw/pUF+\nIa75UbeuHTmcfSyEiE0ZfvSodRGEhMC0aZnb09OtS+iPf8ws69HDjnFYvBi++87G6wc4pmuZNw9i\nYuz4hLwoW9Ye9/TTNuzz/vvtGA/X6w0Jsa4qJ86Bfp64l4qL2FgbNjppkvvtXbrAqFH2/g0eDK+8\nYl1wFy5khrcWlrJlrUvtn//MuS27CzEx0brUpkzJu85+/aBZs8LZc+21NnTZHZcu2VxXrqG5q1bZ\nJISjRrl34RU3nqjI5fopaguOdFAsAAAgAElEQVSiQ4cO0rt378yCL76wbyybNxep3iuW8+ftm9v4\n8d62pHRwRqAUpsPUyZo1IsePZy2bO1cyonguXbKukTJlbNTRqlWZUTTZueEG+2aYnREjbH0rV3pu\n15tv2mM+/9yur10rEhxsXStBQSIxMZn7pqaKXLzoed3FQe/eItdem/XeHz+e8634wgVr+6uv2r+V\nu9ZYcbFvnw3j/eUXu759e9Z7mBvHj4vMmGHDfj3l0CGRG2/M+1mTkmJbC3XqZF73ffeJVKmSGUlX\nSFAXU/40atRIBg8enFkwfLi9JVOnFqneKxbnD+JKuQcxMZ6Fh+bGxo3Wn1ucJCfbMQ2tW2eGgZ46\nZccwOO9t9kgZJ//4h30IpqRkLU9NFfnpp4K7FJxhq8uWiVSoYKN0tm7NPaa/NHGOKZk82a6npVm3\n2qBB7vdPTbURVCXJwYNZ//edkU6rVuV9nLMvynU8VXZXXnac/SCHDuVd94YNIv7+IsOG2XEb5cuL\nPPWUZ9eTB54KhLqYXF1Mvh7N5DrHQGFTI5cmjz5qRzIXNllaeHjmKN/CsmePnWTImQtoxgybVO/N\nN+3IXYCqVWHdOuvaWLIE/vY393W9+KKNQipbNmu5vz/cfHPBXQrt29tl48Y2t9Tq1dCmjY3KEoGd\nO60L5bvvClZvcXDjjTZd9htvWFfKggXWHtc5F1zx97e2liR169rzOCOZnK7WunXzPs4ZyfTrr5m5\nu3780R73yCM2usqVJUvsKPxnnoH69fOuu317m85j5kxbT3S0nRq3tPBERS7XT1FaEMnJyQLIq64R\nLLt3i9Svb2OtfZEJE+yb0F132UFHub2xHjtW+HuUmioya5btpCwqjRpZe8PDC/52nZ5uB7k5B8EV\nlq+/tjb8+qtdT07O3yVxOTB8uHV7FdR1VZwsWGDPv2iRSMeO9u/p2jHvDRo0sGMfRKwLEnK26LKT\nni5Svbrdd8AAW7Z+vcgf/2jHfBiTGchw+rTIddfZEfoXLnhmU3JypqupKAPyXEBdTHlz7NgxAeTD\n7EPrryYK+tBMTbVN3g8/tP8auQ2+eu89uz17mgVPGDtW3KY0KCjJybaJ3qtX/iOA3XH8uLVj0qSi\n2bFrl62nf//83QWXE073SeXKpd//4CQ93aa4cA5yK253X2G4+WaRbt3s902bPHe1Dhli3YrLl2ct\nT0qy/xsg8s9/2o+fn+1XKQgbN9rw52JCBSIftm7dKoB8+eWXmYX/+5/I7beXTjx4djZssPHruYX+\nFYaPPrI+3YK+dezYYf81pk93v/3oUesXLUw47LFjtu6ihtKePCnSt29megKRzLd4T/jxR2tHUVJl\niNiHa0BA8VxTaXP//SJPPultK0QeeMC2WD19oy5JnnxS5A9/KN46L12y41wWLbLfs4uIF1CByIfl\ny5cLID///HNm4ZNP2lsyc2ah683gvfdEFi70fP/wcHtu59twerrtNJ4wQWTUqIL/eA4ftm+Ht9yS\nd2eZk/R0kT//WWTpUrv/XXeJfPNNzv0uXLApDwYMEKlWzfMIoN9+y3QftGhR/D/Cjz6yHXjZ7blw\nwTb3swvv++/b+334cNHPPXKkTdlQnEnzfImUlBLNO1RoVq8uWhDEZYynAuGzndRuU307Y8YLk64g\nO6NG2Xz14kFq440bbcqEp5/O7Fi87z7b+fX3v8N779lYcE8RsR24aWk25r1nT4iPz/uYuDh4912b\nMsDPz8beu87B62TNGjvdZkiInTls7tzMbevX29j77LOsLV5sOyT//Ge7HhqatUO8MGS/r3Xq2JnW\nXDsERWwqhY4dbSexK9u32/kC6tUrmh1gJ6h57bXMTmmlYJQtm/tYAG/Sv79NAe7DqEC4CsT583aZ\n2wxSnuKcctHTeXA/+MDmtHnhBbuekGAHSU2ZYvPRP/wwfPaZ5/P9zphhH8qvv27zz/zwA/z8c97H\nuBs0duZMznOuXWuXzzxjc9n87392/dAh+4M6dChzgNfOnTBggJ0ToFq1zEl2BgzIOkisMIwenXXg\n2M0323kSXOdV2LUrM79R9lw5O3bYh1JpDDZSrhx27LC/22XL7O+4OF4grmACvG2At3AKRDXXuYid\nAlHU0dTOsMvnn8//rTIhwY6WHDwYqlSxZVWr2tm3nPznP3YZGJj/uVNSbLjkzTfDE0/Yt/mKFa1I\n3HNP7sdlF4jt2+0MYZ9/Dvfem7nfL7/YJHXVqsH//Z8N0zt3zrY2UlJg+nS737JltuUSGGjnUX76\nafsAh9yTqRWE7OGgFSrY0MnFi+Gtt2yZq1hkF4gPP8w6TaWigP0/2rAhc4a//EJcr3J8ugVRtWpV\nAgJcNNL5z1DUFsS+fXZZqZKNh3dNd5CdoCArBs63a3dUrmw/KSmZmTdzo1w5O9PY7NnWVVS2rM1Y\nmt+UltHRdl/n9JHNm0P58jldNmvXQufOdr19ezt25KGH7JvX3Ln2OLBvXq+9Zh/kf/tbpjg4OXs2\na6bK1FQrTn5+ns3zvGdPzvQGvXrZVoszfn3xYtvKufXWnALRooV9U1QUV+rVs63KNWsy132YfAXC\nGDPaGFO1NIwpTdzmYXrnHev7r1OnaJXfeaedhvD8eZsqODIy930DAuDuuzMfrHnx6qs23XFuD/tL\nl+xDvFq1rNfQo4d1t5w4kXvdp0/bB7SzxVOmDNxwgxUkp79/717bV+EUCLDzNs+fb1s5t9+eWd68\nuR3g424gUEKCFTynewqswERH2zTHVapYYXK2SrJz4YKdDjO7QNx7rxXbKlXsPitWWNFo3doKh3O6\nzF277EClor4IKFcfZcvaF8XVq+26j7cg8g9zgleBvcBcoDdgPOn9Lo1PUaKYevbsKZ07dy708R6R\nmmoHt/Tr5377Tz+JvPCC56GtiYk2AqhqVfdjFF57zc7mlX0Q2saNNoNlfqkKskfhOKeIjIzMPP+c\nOVmnkTxzxsbUFzQ0ODhY5LHHMtedUUX799v1pUvt+v/9X85jnSlBZs/OvX5n+oNFi+x1//BD5vU5\nZ4orybw+ypVL1642Ncr8+ZdH6G0JQHGGuQIG6AV85hCLCUATT44tyU9RBKJdu3bSv3//rIUDBoj8\n7W+FrjOD997LfKj+9a92zED2/Df799u5bGvWzH1GM3fs3WvDS6+/PutsXufP2+RnvXoV3X4nFy/a\nkaUlMT9uly5Z633oIXsvnEKTliYSEiLiTsT37LGhpe6S3h06JPLf/9qQ2s2b3YfhDh4sUrdusVyG\nchXywgslOpvb5YCnAuFRH4SjwhOOTypQFfjSGPNGcbZmSpPY2NicLqZNm6zfvG/folX+yis2TBRg\nyBDr2vjgg8ztmzfblMbx8fD11zn983nRpIk9Zs8eeOyxzPLp0+HkSRsWmxvuZqcCOHjQhuSuX5+1\nvEwZ67KZPduuz55dPCHA4D7UtUePzKgiPz/byf7LL/Z+udK0qb2f7tJ0r1kDTz5pOxrDwjI79r/9\n1rqcwPZHOPPnKEp2XnnFBnQ43Uy+TH4KAvwF2AgsBgYCZRzlfsA+T1SopD6FbUGkp6dL+fLl5dns\nI1+vvdY2qoKDC1WviFj3Doj861+ZZTffnDnf7969duKT666zaRoKy2efZR6/dq19++7aNXdXz6ef\n2iH+7gaGOXPirF6d+/nOnrXHv/BC4W12ZeJEe87ExNz3SUiw9yr7JPfx8bkPSouLk4ysqVFRmeVN\nm4rce69tFZUte+WNelZKl44dbZr2qxQ8bEF4EuZaHbhHRLJM1ioi6caYfsUpVqXF+fPnSU5OztmC\nyC3MVQSmTrWDwCpXzrvy/fvt0jlHMMDChZmDxzZssBE08+cXLUJi0KDM72vW2Jjt8eNzj+tv3dqO\nyfjgA9tx7gyphcw3+ZAQ98fu25d5PTfcUHibXend20Z55TUOoUoV+Mc/bPZRV+65x/5N3I3tcM3I\ne/Fi5vdWrWzLYd8+W64tCCU31q2zrekmTbxtiffJT0GAG4Agl/UgoJMn6lPSn8K2IA4ePCiATJs2\nLbMwPd2+ITvfPl0TmCUk2DQO48blX7lzPuHcEsiVVJ6n/OpNSxOJiLC2+fvbFBzOSUcef9z2a+RG\nYmLmfYmPLz6bnYwfb/saPE1VUaeOyNChuW9/9107pafrPXnhBfv3PX/etjKKM+eVcnXhTMBYv763\nLSkxKMY+iA8A11fqJEfZFYvbUdRpaXZwWViYXXdtRVSpYkM7v/wy/9QZzlzyub19lNTI3fzq9fOz\nYxjWrLEtiOBgOygI7Iht1xZPdipXhsmTbQvKdWBhUYmKsp+ff7bhrLkNKkxJsWlAzp2zg9uOH897\nisfRo+21ut4TZwvqt9/stQcFFd91KFcXTZrY9CwffeRtS7yOJy4m41AcIMO1dEWPwHYrEAEBdrTx\nN9/YmH7XfEInTtgH6I8/2gds1665Vz5mDAwdmtWFc7ng72+FznUcA1h3VY8eeR87apT9FCd9+th0\nGevXw7Bhue+3bRv85S+2U//uu21ZQecAdrqUhgyxAvL444UyWfEBypbNmbvLR/GkBbHfGPMXY0wZ\nx+dJYH9JG1aSuBUIJ3feaQd/1aiRWbZwYeagro8/zrtyY4r3Lbs0+OyzrBFRpUVoqI3ISkrKKVqu\ndOhgRezNNzP7HQoqEM2a2dbK2bOwfHnhbVYUH8ITgRgJdAGOAUeBTkCRnibGmKeMMTuNMTuMMXOM\nMeWNMY2MMeuMMXuMMZ8bY8rmX1PhcCsQ+/bZh4i76RcTEuzyzjttOom8kub95S/w1VfFaO1VTEhI\nZjLDvAQCbPhxaqoVs1dfLbhA+Pvb0eWHDmkHtaJ4SL4CISInReQ+EblWRGqKyAMicrKwJzTG1MWG\nzkaISCvAH7gPeB34j4g0AxKAEYU9R35cf/31jBgxgiqubqAzZ2wqiXXr7INr1arMbQkJ1of/8sv2\nAZV9zmAnKSk2Nfe2bSVl+tWFcxxDjx42hXheNGpk04WvXWuzxlaqVPDzvfuuXapAKIpH5NuXYIwp\nj31YtwTKO8tF5OEinjfQGHMJqADEAD2ABxzbPwbGU0Kd4bfffju3u+YNgswQ14oV7SA05+TjYAWi\nShVo29Z+cuPgQftGnFeHr5KJUyD+9jfPOu//8Q8bqurMqVRQdu60yxYtCne8ovgYnriY/g+ohU21\n8TNQDyh0ljMROQb8GziMFYZE7EC80yLi7Bk+CpRuliynQDhj7l2jmBISbApusPMzjBvnPvGdM4ur\nxk97Rvv2djxIu3ae7V+1qs3Q6un+2fnwQ1iwIPfxHoqiZMETgWgqIi8ASSLyMdAXKHQb3ZEZ9k6g\nEVAHqAjc4WZXt/GkxpjHjDEbjDEbYmNjC2tGTpxzAzgFwjXT57PP2oeLs/z1123nanacAqEtCM+4\n5hrbr+M6uK0kqVSp6GlUFMWH8CRc9ZJjedoY0wqbj6lhEc55G3BARGIBjDFfYzvBqxhjAhytiHrA\ncXcHi8hUYCpARESEB/N5ekj16tCvX+Z8CK4tCNc31tBQG+G0YUPOOpKSoFatrBFQiqIoVyietCCm\nOt76nwe+BXZhO5QLy2HgBmNMBWOMAW511Pkj4Jy6bCjwTRHOUXC6dbPzNjRvbuPzGzTI3LZwYeaE\nM8ZY18imTTnrGDfODuLSaSwVRbkKyFMgjDF+wBkRSRCRFSLS2BHNNKWwJxSRdcCXwCZgu8OGqcBz\nwNPGmL1AMDCtsOcoEsbYUFfXOZOHDoX3389cDw+3HZ7Jye6PVxRFuQrIUyBEJB0YXdwnFZGXRKS5\niLQSkYdEJEVE9otIRxFpKiIDRSSPeTpLgHfesXHy2WcwE7GzrVV1mVQvPNymkT54MLPs7Fno1Am+\n/75UzFUURSlpPHExLTXGPGOMuc4YU835KXHLSptTp2xkUtmyNifTI4/Y8qQkO0DLVSDuvNOKhus0\noStX2pQRZcqUrt2KoiglhCed1M7xDq6JeARoXPzmeJGkJJu8zhjbQe0MY3WOonYViAA3t+3HH624\ndOlS8rYqiqKUAvkKhIjkM8T1KuH8eTtIDmymT2eYqzuBAJvQb/Nm+OQTu/7DDzZdhHMGM0VRlCsc\nT0ZSD3FXLiKfFL85XuT8+cz015UqQUyM/d6kiU27kX16y+PH4fPPYdo0KyabN9sJexRFUa4SPHEx\ndXD5Xh4blroJuLoEolMnOxYCbAsiOtp+r1jRfXrv8HA7M9muXXa+hLvugl69Ss9eRVGUEsYTF9Of\nXdeNMddg029cXfzpT5nfb7kFate233ftgo0b4d57s7qP2re3y02bYPhw9yOrFUVRrmA8iWLKznmg\ngLmWrzAefxzeftt+X7TITjLjOr8x2HQalSpZgThZ6OS2iqIoly35CoQxJtIY863jswCIorRHOZcG\nXbrAgAGZ685ZmJ2pvrNPUennZ8NdU1Nt/ibXgXSKoihXAZ60IP4NvOX4vAbcJCLjStQqb5CYmDkK\netIkG7KalJSZ6tvPza369FPo3t1+d7qcFEVRrhI86aQ+DMSISDKAMSbQGNNQRA6WqGWljWsUU5ky\ntmVw7lzWVN/u+OEH62pSgVAU5SrDkxbEF0C6y3qao+zqIikp6zgIsOGreQnE4cMwZYoVEneD5xRF\nUa5gPHmqBYhIRg+tiFwsyfmivUb2cRBgH/wffZQ5mVB26tSxWV+ff750bFQURSlFPBGIWGPMH0Tk\nWwBjzJ1AXD7HXHk88ohN+Q1ZWxB5zV4WEJA1YZ+iKMpVhCcCMRKYZYyZ7Fg/CrgdXX1F8847md8b\nNoRRo2x00qRJViRuvNFrpimKongDTwbK7cNO8FMJMCJS6PmoL1vS0+HSJRu5ZIxNrzF5sg1zbdUK\nnnlGBUJRFJ/Dk3EQE4wxVUTknIicNcZUNca8WhrGlRrHj0P58javkpNLl2wHdfZU34qiKD6CJ1FM\nd4jIaeeKiCQAfUrOJC+QlGSXziim06dta2LCBLuuAqEoig/iiUD4G2PKOVeMMYFAuTz2v/JwRik5\no5icQnHokF2qQCiK4oN40kn9KbDcGDPDsT4c+LjkTPIC2QWiTBkoV86OcwAVCEVRfBJPOqnfMMZs\nA24DDPA90KCkDStVsgsE2FDXtm1h/nybakNRFMXH8HT47wnsaOo/AgeAr0rMIm9Qvz6MG2cHvTmp\nVAmSkzPTfiuKovgYufZBGGNCjDEvGmN2A5OBI9gw1+4iMjm3465IQkPhtdegXr3Msj//2bYixo/P\nmepbURTFB8irk/o37Oxx/UWkm4i8i83DdPWRlASnTtnxEE6efhqqVYNXXtE8S4qi+CR5CcQArGvp\nR2PM/4wxt2L7IK4+PvoIgoNteKuTs2fttKNVq7pP9a0oinKVk+uTT0TmicggoDnwE/AUUNMY84Ex\n5vZSsq90cNdJPWwYzJ2rEUyKovgs+b4ai0iSiMwSkX5APWALcHVNGHT+vG0llHMZ3uFM2KcCoSiK\nj1Ig34mInBKRKSLSo6QM8gpJSbb1YFw8aM6U3yoQiqL4KOpch6xzQTgJCgJ/f5g3zzs2KYqieBkN\nzwG4805o2TJrWVAQpKXZUdWKoig+iLYgAO64w457cOXWW+3y++9L3x5FUZTLABUIgKNH4cSJrGXO\nFsXu3aVvj6IoymWAupgABg+2HdQ//phZdvy4XQYGescmRVEUL6MtCMiMYnLlm2/s0pnRVVEUxcdQ\ngQD3UUydO9tlz56lb4+iKMplgLqYwL1AdOsGZ85kDphTFEXxMbQFAdbF5JxFzhUVB0VRfBhtQQC8\n/jo0buxtKxRFUS4rVCAAhg/3tgWKoiiXHaXuYjLGhBpjtrh8zhhjxhhjqhljlhpj9jiWpZMEKS0N\nNm6EuLhSOZ2iKMqVQqkLhIhEiUiYiIQB7YHzwDxshtjlItIMWE5pZYw9fRoiImD27FI5naIoypWC\ntzupbwX2icgh4E7gY0f5x8BdpWKBu7kgFEVRFK8LxH3AHMf3miISA+BYXuvuAGPMY8aYDcaYDbGx\nsUW3ICnJLt1FMSmKovgwXhMIY0xZ4A/AFwU5TkSmikiEiETUqFGj6IZoC0JRFMUt3mxB3AFsEpHf\nHeu/G2NqAziWJ0vFChUIRVEUt3hTIO4n070E8C0w1PF9KPBNqVjRrBl8+im0bl0qp1MURblSMCJS\n+ic1pgJwBGgsIomOsmBgLlAfOAwMFJFTedUTEREhGzZsKGlzFUVRriqMMRtFJCK//bwyUE5EzgPB\n2crisVFNpcvx47B3L3TsCOXLl/rpFUVRLle8HcXkfSIj4eabIT7e25YoiqJcVqhAJCba5TXXeNcO\nRVGUywwViMRE8PfXcRCKoijZUIFITITKle2Uo4qiKEoGKhCJiepeUhRFcYOm+37mGRg6NP/9FEVR\nfAwViLZtvW2BoijKZYm6mJYsgU2bvG2FoijKZYcKxMiR8Pbb3rZCURTlskMFQjupFUVR3OLbAiGi\nAqEoipILvi0Q58/bOalVIBRFUXLg2wKhaTYURVFyxbfDXIODYfVqaNTI25YoiqJcdvi2QJQrB126\neNsKRVGUyxLfdjEdOgQffwyn8pyXSFEUxSfxbYFYtw6GDbOTBimKoihZ8G2B0E5qRVGUXFGBABUI\nRVEUN6hAGAOVKnnbEkVRlMsOFYjKlcHPt2+DoiiKO3z7yfj887BqlbetUBRFuSzx7XEQ115rP4qi\nKEoOfLsFMWcOfPONt61QFEW5LPFtgXjzTfjf/7xthaIoymWJb7uYEhPh+uu9bYWilAiXLl3i6NGj\nJCcne9sUxUuUL1+eevXqUaZMmUIdrwKhYyCUq5SjR48SFBREw4YNMcZ42xyllBER4uPjOXr0KI0K\nmZDUd11MOlmQcpWTnJxMcHCwioOPYowhODi4SC1I3xWICxcgNdWOg1CUqxQVB9+mqH9/33UxlS9v\nk/QFBnrbEkVRlMsS321B+PlB7dpQpYq3LVGUq5L4+HjCwsIICwujVq1a1K1bN2P94sWLHtUxfPhw\noqKiPD5nTEwMffr0oW3btrRo0YI//OEPee5/6tQpPvzwwzz3+eKLLzDGsHfvXo/tuFrwXYE4dAjG\nj4f9+71tiaJclQQHB7Nlyxa2bNnCyJEjeeqppzLWy5YtC9iO1PT09FzrmDFjBqGhoR6f8/nnn6dv\n375s3bqVXbt28eqrr+a5vycCMWfOHLp168Znn33msR2FITU1tUTrLwy+62KKjoaXX4Zbb4XGjb1t\njaKUKGPGjGHLli3FWmdYWBjvvPNOgY/bu3cvd911F926dWPdunUsWLCAl19+mU2bNnHhwgUGDRrE\niy++CEC3bt2YPHkyrVq1onr16owcOZJFixZRoUIFvvnmG67NlgkhJiaGevXqZay3adMm4/vEiRP5\n+uuvSU5O5t577+XFF19k3LhxREVFERYWRu/evZk4cWKW+s6cOcO6detYvnw5AwYM4Pnnn8/YNmHC\nBObMmYOfnx/9+vXjX//6F9HR0YwcOZL4+Hj8/f35+uuv2bt3L5MnT2b+/PkAjBw5km7dujF48GDq\n1avH448/zvfff8+YMWOIj49n2rRpXLx4kZCQED755BMCAwM5ceIEjz/+OAcOHMAYw9SpU5k/fz71\n6tVj1KhRADz33HM0aNCAP/3pTwX+m+SG77YgNNW3oniNXbt2MWLECDZv3kzdunWZOHEiGzZsYOvW\nrSxdupRdu3blOCYxMZGbb76ZrVu30rlzZ6ZPn55jn9GjRzN06FB69OjBhAkTiImJAWDhwoUcPnyY\ndevWsWXLFtasWcOaNWuYOHEioaGhbNmyJYc4AHz99df069eP5s2bU7FiRbZt2wZAZGQkixYtYv36\n9WzdupWxY8cCcP/99/PUU0+xdetW1qxZk0PA3FGxYkVWr17NwIEDGThwIL/++itbt26lSZMmzJw5\nE4BRo0bRs2dPtm3bxsaNG7n++ut55JFHMranpaXxxRdfcP/993t0/z3Fd1sQKhCKD1GYN/2SpEmT\nJnTo0CFjfc6cOUybNo3U1FSOHz/Orl27aNGiRZZjAgMDueOOOwBo3749K1euzFFvnz592LdvH99/\n/z2LFi2iXbt27Ny5kyVLlmSsA5w7d47o6Oh8H+Bz5sxh3LhxANx3333MmTOHNm3asGzZMh5++GEC\nHUEu1apVIyEhgbi4OPr37w/YQWqeMGjQoIzv27Zt48UXX+T06dOcPXuWfv36AfDTTz9luLgCAgKo\nXLkylStXJigoiO3bt3Po0CE6duxI1apVPTqnp6hAqEAoSqlTsWLFjO979uzhv//9L+vXr6dKlSoM\nHjzYbey+s98CwN/fP1effXBwMA8++CAPPvggvXv3ZtWqVYgIzz//PCNGjMiyb14dz7Gxsfz888/8\n9ttvGGNITU2lTJkyTJgwARFxG0LqriwgICBLP0v2a3O9F0OGDGHRokW0atWKjz76iLVr1+ZZ94gR\nI5g5cyYHDx7k8ccfz/VaCovvupjOnLHLoCDv2qEoPs6ZM2cICgqicuXKxMTEsHjx4kLXtXz5ci5c\nuJBR74EDB6hfvz69evVi2rRpJCUlAXaUeVxcHEFBQZw9e9ZtXXPnzmXEiBEcOnSIgwcPcvToUerU\nqcPatWu5/fbbmTZtWsa5Tp06RdWqValevTqRkZGAFYLz58/ToEEDdu7cycWLF0lISOCHH37I1f6k\npCRq1arFpUuXmD17dkZ59+7dMzrT09LSOON4fg0YMIDIyEi2bNnCbbfdVuj7lhteEQhjTBVjzJfG\nmN+MMbuNMZ2NMdWMMUuNMXscy+JtK2XnxRfh9Gnw9y/R0yiKkjfh4eG0aNGCVq1a8eijj9K1a9dC\n1/Xrr78SHh5OmzZt6NKlC0888QTt2rWjT58+3Hvvvdxwww20bt2aP/7xj5w7d46aNWsSERFB69at\nM1xJTubMmcPdd9+dpWzAgAHMnj2bfv360bt3byIiIggLC+M///kPALNmzeKtt96iTZs2dOvWjdjY\nWBo1asRdd91F69atGUxt0dkAAA7fSURBVDJkCOHh4bna/8orr9CxY0d69uyZxcU2efJkFi9eTOvW\nrYmIiOC3334DrBvrpptu4v7778evBCY+MyJS7JXme1JjPgZWishHxpiyQAXg78ApEZlojBkHVBWR\n5/KqJyIiQjZs2FAKFivKlcfu3bu5XpNRXtWkp6cTFhbG/PnzaZxLNKa7/wNjzEYRiciv/lJvQRhj\nKgM3AdMAROSiiJwG7gQ+duz2MXBXiRry4YfgUH1FUZQrje3bt9OkSRN69+6dqzgUFW90UjcGYoEZ\nxpi2wEbgSaCmiMQAiEiMMcZteIEx5jHgMYD69esX3oovvoDkZHjqqcLXoSiK4iVat27NgQMHSvQc\n3uiDCADCgQ9EpB2QBIzL+5BMRGSqiESISESNGjUKb4VmclUURckTbwjEUeCoiKxzrH+JFYzfjTG1\nARzLkyVqxZkzKhCKoih5UOoCISIngCPGGGeClVuBXcC3wFBH2VCgZCeL1haEoihKnnhroNyfgVmO\nCKb9wHCsWM01xowADgMDS9SCixdVIBRFUfLAKwIhIlsAdyFWt5aaEQkJkEcWSUVRikZ8fDy33mp/\n0idOnMDf3x9nv+H69euzjIzOi+nTp9OnTx9q1aqVY9vq1at5+umnSUlJISUlhQceeIAXXngh17o2\nbdrEyZMn6d27d677jBo1isjISA4dOuTzEy75bqoNsHNCKIpSIjjTfQOMHz+eSpUq8cwzzxS4nunT\npxMeHu5WIIYOHcr8+fNp1aoVaWlp+c4dsWnTJnbs2JGrQKSlpfHtt99Sp04dVq9eTbdu3QpsryeI\nCCJSIoPbipPL27qS4tgxeOghWL/e25YoSulxyy05P++/b7edP+9+uyNbKHFxObcVgY8//piOHTsS\nFhbGn/70J9LT00lNTeWhhx6idevWtGrVikmTJvH555+zZcsWBg0a5HaiodjY2Azh8Pf3zxh9fO7c\nOYYNG0bHjh1p164dkZGRXLhwgVdeeYVZs2YRFhbGl19+mcOuZcuW0a5dOx577DHmzJmTUX727FmG\nDh1K69atadOmTUbq7u+++47w8HDatm3L7bffDtg5KVyTIzZv3pyjR4+yd+9eWrVqxciRIwkPDycm\nJobHHnuMiIgIWrZsySuvvJJxzLp16+jcuTNt27alU6dOnD9/ni5durBjx46MfTp16sTOnTuL9HfI\nD99sQcTEwKefwsCS7eZQFCUnO3bsYN68eaxZs4aAgAAee+wxPvvsM5o0aUJcXBzbt28H4PTp01Sp\nUoV3332XyZMnExYWlqOuMWPG0KxZM7p3784dd9zBkCFDKFeuHK+88gq9e/dm5syZJCQk0KlTp4xM\nqTt27Mg1u+2cOXO4//77ueOOO3jppZf473//S0BAAOPHj6dGjRps374dEeH06dOcOHGCJ554gpUr\nV9KgQQNOnTqV77Xv2rWLGTNmZORVmjhxItWqVSM1NZXu3btz77330rhxY+677z6++uorwsPDSUxM\npFy5chmJ+f79739npENv2bJlYf8MHuGbAqGZXBVf5Kefct9WoULe26tXz3t7AVi2bBm//vorERG2\nG/LChQtcd9119OrVi6ioKJ588kn69OmT8UaeFy+//DIPPfQQS5Ys4ZNPPuHzzz9n2bJlGem9nXM8\nJCcnc/jw4TzrSklJYcmSJbz33ntUrFiR8PBwli9fTq9evVi2bFlGq8EYQ9WqVZk3bx7du3enQYMG\ngE35nR+epDlPSUmhfv36GTmbrnE8p+677z7CwsKYOHEi06dPZ/jw4fmer6ioQCiKUqqICA8//DD/\n/Oc/c2zbtm0bixYtYtKkSXz11VdMnTo13/qaNm1K06ZNefTRRwkODiYxMRERYf78+TRp0iTLvitW\nrMi1nu+++47ExMSMt/KkpCSqVatGr1693Kb3zi3ld17pvT1Jc55bvRUrVuSWW27h22+/5auvvir2\nGQLd4Zt9ECoQiuI1brvtNubOnUtcXBxgo50OHz5MbGwsIsLAgQMzpiAF8kzJ/d133+FMOBodHU25\ncuUICgqiV69eTJo0KWO/zZs351vXnDlzMuZWOHjwIPv372fRokUkJydz++23M3nyZMAKQ0JCAl27\nduWHH37g0KFDABkupoYNG7Jx40bARmsdOXLE7flyS3PesmVLDh06lHH9Z86cIS0tDYBHHnmE0aNH\n06VLl4yWRUnimwIhAlWrqkAoihdo3bo1L730Erfddhtt2rTh9ttv5/fff+fIkSPcdNNNhIWF8eij\njzJhwgQAhg8fziOPPOK2k3rmzJmEhoYSFhbGsGHDmD17Nn5+frz00kucP3+e1q1b07JlS8aPHw9A\njx492Lp1K+3atcvSSX3u3DmWL1+eMWMdWDHp1KkT3333HS+99BK///47rVq1IiwsjJUrV1KzZk0+\n+OAD7rzzTtq2bcuDDz4IwMCBA/n9999p164d06ZNyzWRXm5pzsuVK8ecOXN44oknMjq/U1JSANsx\nXaFChVJxL4GX0n0XF5ruW1FyR9N9X30cOXKEnj17snv3bo/HaFxR6b4VRVGUgjNjxgy6dOnChAkT\nSm0An292UiuKolxhDB8+vNRcS060BaEoVzFXsgtZKTpF/furQCjKVUr58uWJj49XkfBRRIT4+HjK\nly9f6DrUxaQoVyn16tXj6NGjxMbGetsUxUuUL1+eevXqFfp4FQhFuUopU6YMjRo18rYZyhWMupgU\nRVEUt6hAKIqiKG5RgVAURVHcckWPpDbGxAKHCnl4dSCuGM25UvDF6/bFawbfvG5fvGYo+HU3EJEa\n+e10RQtEUTDGbPBkqPnVhi9ety9eM/jmdfviNUPJXbe6mBRFURS3qEAoiqIobvFlgch/JpKrE1+8\nbl+8ZvDN6/bFa4YSum6f7YNQFEVR8saXWxCKoihKHqhAKIqiKG7xSYEwxvQ2xkQZY/YaY8Z5257i\nwhgz3Rhz0hizw6WsmjFmqTFmj2NZ1VFujDGTHPdgmzEm3HuWFw1jzHXGmB+NMbuNMTuNMU86yq/a\nazfGlDfGrDfG/H975xqiRRnF8d8f1/WSsZKpSBuZZKCGrVi2ZuF2pSK6kB8yS6slSUQSAk2KrA9B\nQWkUkn0oKugi3c0vJppSVFqraymlqVl5IaXU0g+advrwnNeGZbTL7rsv+875wTDznOfZd89/dnbO\nO+eZObPeNT/q9rMlrXbNiyTVur2Ht7d4/+BK+t8eJHWTtE7SEm8XQfN2SV9LapX0pdvKfnwXLkBI\n6gYsAK4FhgMTJQ2vrFcdxkvANW1sDwDLzWwosNzbkPQP9WUq8Fwn+VgOjgL3m9kwoBGY7n/TatZ+\nGLjczM4HGoBrJDUCTwDzXfM+oNnHNwP7zOwcYL6P66rcB3yTaRdBM8BlZtaQed6h/Me3mRVqAcYC\nSzPtOcCcSvvVgfoGAxsy7U3AIN8eBGzy7eeBiXnjuvoCvA9cVRTtQG9gLXAR6WnaGrcfP9aBpcBY\n367xcaq07/9Da72fDC8HlgCqds3u/3bg9Da2sh/fhbuCAM4Afsq0d7itWhloZrsBfD3A7VW5HzyN\nMApYTZVr91RLK7AHWAZsBfab2VEfktV1XLP3HwD6da7HHcLTwCzgT2/3o/o1AxjwoaQWSVPdVvbj\nu4jvg8h723cR7/Wtuv0gqQ/wNjDTzH47yYvdq0K7mR0DGiT1Bd4FhuUN83WX1yzpemCPmbVIaiqZ\nc4ZWjeYM48xsl6QBwDJJ355kbIfpLuIVxA7gzEy7HthVIV86g58lDQLw9R63V9V+kNSdFBxeNbN3\n3FwI7Wa2H1hJmn/pK6n0xS+r67hm768Dfu1cT9vNOOAGSduBN0hppqepbs0AmNkuX+8hfRkYQycc\n30UMEF8AQ/3Oh1rgVmBxhX0qJ4uBKb49hZSfL9kn+x0PjcCB0uVqV0PpUuEF4Bszm5fpqlrtkvr7\nlQOSegFXkiZuPwIm+LC2mkv7YgKwwjxB3VUwszlmVm9mg0n/tyvMbBJVrBlA0imSTi1tA1cDG+iM\n47vSky8VmvC5DthMytk+WGl/OlDX68Bu4A/St4hmUs51OfCdr0/zsSLdzbUV+Bq4oNL+t0P3JaRL\n6K+AVl+uq2btwEhgnWveADzs9iHAGmAL8CbQw+09vb3F+4dUWkM79TcBS4qg2fWt92Vj6ZzVGcd3\nlNoIgiAIciliiikIgiD4F0SACIIgCHKJABEEQRDkEgEiCIIgyCUCRBAEQZBLBIigUEgaKOk1Sdu8\nbMFnkm6ukC9Nki7OtO+VNLkSvgRBHkUstREUFH+g7j3gZTO7zW1nATeU8XfW2N91gtrSBBwEPgUw\ns4Xl8iMI/g/xHERQGCRdQXqgbHxOXzfgcdJJuwewwMye95o/j5AqgZ4HtAC3m5lJGg3MA/p4/51m\ntlvSStJJfxzpqdbNwENALfALMAnoBXwOHAP2AjOAK4CDZvakpAZgIalS61bgbjPb55+9GrgM6As0\nm9nHHbeXguBvIsUUFIkRpLLYeTSTShJcCFwI3CPpbO8bBcwkvT9kCDDOaz89C0wws9HAi8Bjmc/r\na2bjzewp4BOg0cxGkWoIzTKz7aQAMN9Sjf+2J/lXgNlmNpL0NOzcTF+NmY1xn+YSBGUiUkxBYZG0\ngFSm4wjwAzBSUqmmTx3phStHgDVmtsN/ppX0zo39pCuKZV41thupzEmJRZntemCRF1SrBb7/B7/q\nSAFmlZteJpWMKFEqRtjivgRBWYgAERSJjcAtpYaZTZd0OvAl8CMww8yWZn/AU0yHM6ZjpP8bARvN\nbOwJftehzPazwDwzW5xJWbWHkj8lX4KgLESKKSgSK4CekqZlbL19vRSY5qkjJJ3rlTNPxCagv6Sx\nPr67pBEnGFsH7PTtKRn778CpbQeb2QFgn6RL3XQHsKrtuCAoN/HtIygMPrF8EzBf0izS5PAhYDYp\nhTMYWOt3O+0FbjrJZx3xdNQznhKqIb2bYGPO8EeANyXtJE1Ml+Y2PgDeknQjaZI6yxRgoaTewDbg\nrv+uOAjaR9zFFARBEOQSKaYgCIIglwgQQRAEQS4RIIIgCIJcIkAEQRAEuUSACIIgCHKJABEEQRDk\nEgEiCIIgyOUvtB6wX7PonlEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6cd050a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matlotlib code to plot the loss and accuracies\n",
    "eval_indices = range(0, generations, eval_every)\n",
    "# Plot loss over time\n",
    "plt.plot(eval_indices, train_loss, 'k-')\n",
    "plt.title('Softmax Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Softmax Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot train and test accuracy\n",
    "plt.plot(eval_indices, train_acc, 'k-', label='Train Set Accuracy')\n",
    "plt.plot(eval_indices, test_acc, 'r--', label='Test Set Accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6df635da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6df6353c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6cd2a1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6e0da7828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoYAAAFfCAYAAADTUw0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSTEEACBJ8r82weaQ7we/TAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6e0d6e668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some samples\n",
    "# Plot the 10 of the last batch results:\n",
    "actuals = rand_y[0:10]\n",
    "predictions = np.argmax(temp_train_preds,axis=1)[0:10]\n",
    "images = np.squeeze(rand_x[0:10])\n",
    "\n",
    "Nrows = 2\n",
    "Ncols = 5\n",
    "# plot with various axes scales and set the Figure Size for the image\n",
    "plt.figure(1)\n",
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(Nrows, Ncols, i+1)\n",
    "    plt.imshow(images[i], cmap='Greys_r')\n",
    "    plt.title('Actual: ' + str(actuals[i]) + ' Pred: ' + str(predictions[i]), fontsize=10)\n",
    "    plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "# Adjust the subplot layout, because the logit one may take more space\n",
    "# than usual, due to y-tick labels like \"1 - 10^{-3}\"\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 28, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(315,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def Create28x28GSImage(chunk):\n",
    "    IDT = chunk\n",
    "    #display(chunk)\n",
    "    new_data = []\n",
    "    for i in range(0, len(IDT), 8):\n",
    "        new_data.append(IDT[i:i+8])  # 8 digit binary list\n",
    "    int_data = [] \n",
    "    for i in new_data:\n",
    "        i=str(i)\n",
    "        #display(ord(i[0]))\n",
    "        int_data = bytearray((ord(i[0]), ord(i[1]), ord(i[2]), ord(i[3]), ord(i[4]), ord(i[5]), ord(i[6]), ord(i[7])))        \n",
    "        #int_data.append(int(bin(i),2)) \n",
    "    a= bytearray(int_data)\n",
    "    # Convert the data to Binary\n",
    "    #ISA = np.select([IDT <= .5, IDT>.5], [np.zeros_like(IDT), np.ones_like(IDT)])\n",
    "    # Create the Numpy array of converted data\n",
    "    img = np.array(a) #, dtype = np.uint8)\n",
    "    #display(img)\n",
    "    # Create a grayscale image using CV2 function\n",
    "    grayscale = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 0)\n",
    "    # Recsale created Grascale Image to 28x28\n",
    "    Image28x28 = cv2.resize(grayscale, (28,28))\n",
    "    \n",
    "    return Image28x28\n",
    "\n",
    "PCPTSTIMGLst = []\n",
    "PCPIDX = 0\n",
    "BinaryFilePath = Base_DIR + '/Advantech.pcap'\n",
    "TestLableX = []\n",
    "\n",
    "with open(BinaryFilePath, \"rb\") as f:\n",
    "    for chunk in iter(lambda: f.read(128), b\"\"):\n",
    "        ImageGSI = Create28x28GSImage(chunk)\n",
    "        PCPTSTIMGLst.append(ImageGSI)      \n",
    "        TestLableX.append(1)\n",
    "        # Generate the Image Iname\n",
    "        imagename = 'PCPIMG_'+str(PCPIDX)+'.png'\n",
    "        # Save Original and convered Image\n",
    "        #cv2.imwrite(imagename,ImageGSI)\n",
    "        #Increment Index\n",
    "        PCPIDX += 1\n",
    "            \n",
    "PCPNewTestData3 = np.array(PCPTSTIMGLst)\n",
    "TestLable3 = np.array(TestLableX)\n",
    "display(PCPNewTestData3.shape)\n",
    "display(TestLable3.shape)\n",
    "display(train_labels.shape)\n",
    "display(test_xdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation # 5. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.20)\n",
      "Generation # 10. Train Loss: 0.02. Train Acc (Test Acc): 99.70 (56.20)\n",
      "Generation # 15. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (56.20)\n",
      "Generation # 20. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (56.20)\n",
      "Generation # 25. Train Loss: 0.03. Train Acc (Test Acc): 99.50 (56.20)\n",
      "Generation # 30. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (54.40)\n",
      "Generation # 35. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.00)\n",
      "Generation # 40. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (57.20)\n",
      "Generation # 45. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (57.20)\n",
      "Generation # 50. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (57.20)\n",
      "Generation # 55. Train Loss: 0.00. Train Acc (Test Acc): 99.60 (56.00)\n",
      "Generation # 60. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (54.40)\n",
      "Generation # 65. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (54.40)\n",
      "Generation # 70. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.40)\n",
      "Generation # 75. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.40)\n",
      "Generation # 80. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (54.40)\n",
      "Generation # 85. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (54.40)\n",
      "Generation # 90. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (57.40)\n",
      "Generation # 95. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (57.40)\n",
      "Generation # 100. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.00)\n",
      "Generation # 105. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.00)\n",
      "Generation # 110. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (56.20)\n",
      "Generation # 115. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (57.00)\n",
      "Generation # 120. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (56.20)\n",
      "Generation # 125. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.20)\n",
      "Generation # 130. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (57.00)\n",
      "Generation # 135. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (57.00)\n",
      "Generation # 140. Train Loss: 0.03. Train Acc (Test Acc): 99.80 (57.00)\n",
      "Generation # 145. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (57.00)\n",
      "Generation # 150. Train Loss: 0.01. Train Acc (Test Acc): 99.90 (56.00)\n",
      "Generation # 155. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.80)\n",
      "Generation # 160. Train Loss: 0.01. Train Acc (Test Acc): 99.50 (56.00)\n",
      "Generation # 165. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (55.80)\n",
      "Generation # 170. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 175. Train Loss: 0.01. Train Acc (Test Acc): 99.90 (56.00)\n",
      "Generation # 180. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.40)\n",
      "Generation # 185. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.20)\n",
      "Generation # 190. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (56.00)\n",
      "Generation # 195. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (56.00)\n",
      "Generation # 200. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.00)\n",
      "Generation # 205. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (54.20)\n",
      "Generation # 210. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (55.80)\n",
      "Generation # 215. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 220. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 225. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (56.60)\n",
      "Generation # 230. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 235. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (54.20)\n",
      "Generation # 240. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 245. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 250. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (55.80)\n",
      "Generation # 255. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 260. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (55.80)\n",
      "Generation # 265. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 270. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (54.20)\n",
      "Generation # 275. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (56.60)\n",
      "Generation # 280. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.60)\n",
      "Generation # 285. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.60)\n",
      "Generation # 290. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.60)\n",
      "Generation # 295. Train Loss: 0.03. Train Acc (Test Acc): 99.70 (55.80)\n",
      "Generation # 300. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 305. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 310. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (56.80)\n",
      "Generation # 315. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (56.80)\n",
      "Generation # 320. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 325. Train Loss: 0.00. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 330. Train Loss: 0.01. Train Acc (Test Acc): 99.60 (56.80)\n",
      "Generation # 335. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (56.60)\n",
      "Generation # 340. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 345. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 350. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (57.20)\n",
      "Generation # 355. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 360. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (54.20)\n",
      "Generation # 365. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 370. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 375. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.60)\n",
      "Generation # 380. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.60)\n",
      "Generation # 385. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 390. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.60)\n",
      "Generation # 395. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.60)\n",
      "Generation # 400. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 405. Train Loss: 0.02. Train Acc (Test Acc): 99.70 (56.60)\n",
      "Generation # 410. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (56.60)\n",
      "Generation # 415. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (56.60)\n",
      "Generation # 420. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (54.20)\n",
      "Generation # 425. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 430. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.80)\n",
      "Generation # 435. Train Loss: 0.01. Train Acc (Test Acc): 99.90 (56.80)\n",
      "Generation # 440. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.20)\n",
      "Generation # 445. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 450. Train Loss: 0.01. Train Acc (Test Acc): 99.70 (55.80)\n",
      "Generation # 455. Train Loss: 0.00. Train Acc (Test Acc): 99.70 (55.80)\n",
      "Generation # 460. Train Loss: 0.00. Train Acc (Test Acc): 100.00 (55.80)\n",
      "Generation # 465. Train Loss: 0.02. Train Acc (Test Acc): 99.80 (55.80)\n",
      "Generation # 470. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (55.80)\n",
      "Generation # 475. Train Loss: 0.01. Train Acc (Test Acc): 99.80 (56.40)\n",
      "Generation # 480. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.20)\n",
      "Generation # 485. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.20)\n",
      "Generation # 490. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (56.80)\n",
      "Generation # 495. Train Loss: 0.00. Train Acc (Test Acc): 99.90 (57.20)\n",
      "Generation # 500. Train Loss: 0.02. Train Acc (Test Acc): 99.60 (56.80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.799999999999997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_xdata2 = PCPNewTestData3\n",
    "test_labels2 = TestLable3\n",
    "\n",
    "# Start training loop\n",
    "train_loss2 = []\n",
    "train_acc2 = []\n",
    "test_acc2 = []\n",
    "for i in range(generations):\n",
    "    rand_index = np.random.choice(len(train_xdata), size=batch_size)\n",
    "    rand_x = train_xdata[rand_index]\n",
    "    rand_x = np.expand_dims(rand_x, 3)\n",
    "    rand_y = train_labels[rand_index]\n",
    "    train_dict = {x_input: rand_x, y_target: rand_y}\n",
    "    \n",
    "    sess.run(train_step, feed_dict=train_dict)\n",
    "    temp_train_loss, temp_train_preds = sess.run([loss, prediction], feed_dict=train_dict)\n",
    "    temp_train_acc = get_accuracy(temp_train_preds, rand_y)\n",
    "    \n",
    "    if (i+1) % eval_every == 0:\n",
    "        eval_index = np.random.choice(len(test_xdata2), size=evaluation_size)\n",
    "        #display(len(test_xdata),eval_index,len(test_labels))\n",
    "        eval_x = test_xdata2[eval_index]\n",
    "        eval_x = np.expand_dims(eval_x, 3)\n",
    "        eval_y = test_labels2[eval_index]\n",
    "        test_dict2 = {eval_input: eval_x, eval_target: eval_y}\n",
    "        test_preds2 = sess.run(test_prediction, feed_dict=test_dict)\n",
    "        temp_test_acc = get_accuracy(test_preds2, eval_y)\n",
    "        \n",
    "        # Record and print results\n",
    "        train_loss2.append(temp_train_loss)\n",
    "        train_acc2.append(temp_train_acc)\n",
    "        test_acc2.append(temp_test_acc)\n",
    "        acc_and_loss = [(i+1), temp_train_loss, temp_train_acc, temp_test_acc]\n",
    "        acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "        print('Generation # {}. Train Loss: {:.2f}. Train Acc (Test Acc): {:.2f} ({:.2f})'.format(*acc_and_loss))\n",
    "        \n",
    "display(np.mean(temp_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
